model_name_or_path: unsloth/llama-3-8b-Instruct
model_dtype: bfloat16
top_k: -1
top_p: 0.95
temperature: 0.7
max_tokens: 1536
sample_batch_size: 4
dataset_kwargs:
  MATH:
    problem_size: 16
    sample_size: 40
