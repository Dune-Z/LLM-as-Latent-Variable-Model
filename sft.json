Traceback (most recent call last):
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 134, in <module>
    train_dataset = load_dataset(script_args.train_set_path)["train"].shuffle(seed=42)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 1735, in dataset_module_factory
    raise FileNotFoundError(f"Couldn't find any data file at {relative_to_absolute_path(path)}.")
FileNotFoundError: Couldn't find any data file at /home/cyc2202/LLM-as-Latent-Variable-Model/outputs/gemma-2-2b-it-restem/round-1/sample_output.jsonl.
Traceback (most recent call last):
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 145, in <module>
    train_dataset = load_json_dataset(script_args.train_set_path)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 140, in load_json_dataset
    data = json.load(f)
           ^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/json/__init__.py", line 293, in load
    return loads(fp.read(),
           ^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 2 column 1 (char 317)
Traceback (most recent call last):
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 139, in <module>
    column_names = list(train_dataset.features)
                        ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'DatasetDict' object has no attribute 'features'

Map (num_proc=16):   0%|          | 0/3448 [00:00<?, ? examples/s]
Map (num_proc=16):   0%|          | 0/3448 [00:00<?, ? examples/s]
multiprocess.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 678, in _write_generator_to_queue
    for i, result in enumerate(func(**kwargs)):
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3428, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3320, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 133, in cot_prefix
    sample["completion"] = sample["Answer"][0]
                           ~~~~~~^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 277, in __getitem__
    value = self.data[key]
            ~~~~~~~~~^^^^^
KeyError: 'Answer'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 140, in <module>
    train_dataset = train_dataset.map(cot_prefix, remove_columns=column_names, num_proc=16)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3147, in map
    for rank, done, content in iflatmap_unordered(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 718, in iflatmap_unordered
    [async_result.get(timeout=0.05) for async_result in async_results]
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/utils/py_utils.py", line 718, in <listcomp>
    [async_result.get(timeout=0.05) for async_result in async_results]
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/multiprocess/pool.py", line 774, in get
    raise self._value
KeyError: 'Answer'

Map (num_proc=16):   0%|          | 0/3448 [00:00<?, ? examples/s]
Map (num_proc=16): 100%|██████████| 3448/3448 [00:00<00:00, 33866.86 examples/s]
Map (num_proc=16): 100%|██████████| 3448/3448 [00:00<00:00, 19493.17 examples/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': model_init_kwargs, max_seq_length. Will not be supported from version '0.13.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:175: UserWarning: You passed `model_init_kwargs` to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:202: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
--- Logging error ---
Traceback (most recent call last):
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 1110, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 953, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 687, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 377, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 152, in <module>
    trainer = SFTTrainer(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py", line 209, in __init__
    model = AutoModelForCausalLM.from_pretrained(model, **model_init_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4097, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 963, in __init__
    super().__init__(config)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 1432, in __init__
    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1235, in from_model_config
    generation_config = cls.from_dict(config_dict, return_unused_kwargs=False, _from_model_config=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1093, in from_dict
    config = cls(**{**config_dict, **kwargs})
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 475, in __init__
    self.validate(is_init=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 751, in validate
    logger.warning_once(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/logging.py", line 328, in warning_once
    self.warning(*args, **kwargs)
Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'
Arguments: (<class 'UserWarning'>,)

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.91it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.20it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.96it/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(

Map:   0%|          | 0/3448 [00:00<?, ? examples/s]
Map:  29%|██▉       | 1000/3448 [00:00<00:00, 2709.55 examples/s]
Map:  58%|█████▊    | 2000/3448 [00:00<00:00, 2888.02 examples/s]
Map:  87%|████████▋ | 3000/3448 [00:01<00:00, 2951.29 examples/s]
Map: 100%|██████████| 3448/3448 [00:01<00:00, 2959.30 examples/s]
Map: 100%|██████████| 3448/3448 [00:01<00:00, 2915.00 examples/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.
  warnings.warn(
[2024-11-13 02:31:55,804] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using auto half precision backend
***** Running training *****
  Num examples = 3,448
  Num Epochs = 3
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 4
  Total optimization steps = 321
  Number of trainable parameters = 2,614,341,888
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yutongyin2028 (yutongyin). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/cyc2202/LLM-as-Latent-Variable-Model/wandb/run-20241113_023157-rmxsrdag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ./sft_models
wandb: ⭐️ View project at https://wandb.ai/yutongyin/huggingface
wandb: 🚀 View run at https://wandb.ai/yutongyin/huggingface/runs/rmxsrdag

  0%|          | 0/321 [00:00<?, ?it/s]/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

  0%|          | 1/321 [00:03<20:21,  3.82s/it]
  1%|          | 2/321 [00:06<17:32,  3.30s/it]
  1%|          | 3/321 [00:09<17:03,  3.22s/it]
  1%|          | 4/321 [00:12<16:21,  3.10s/it]
  2%|▏         | 5/321 [00:15<16:01,  3.04s/it]
                                               

  2%|▏         | 5/321 [00:15<16:01,  3.04s/it]
  2%|▏         | 6/321 [00:18<16:14,  3.09s/it]
  2%|▏         | 7/321 [00:22<17:16,  3.30s/it]
  2%|▏         | 8/321 [00:25<16:19,  3.13s/it]
  3%|▎         | 9/321 [00:28<15:57,  3.07s/it]
  3%|▎         | 10/321 [00:31<16:09,  3.12s/it]
                                                

  3%|▎         | 10/321 [00:31<16:09,  3.12s/it]
  3%|▎         | 11/321 [00:34<16:02,  3.11s/it]
  4%|▎         | 12/321 [00:37<16:01,  3.11s/it]
  4%|▍         | 13/321 [00:40<15:12,  2.96s/it]
  4%|▍         | 14/321 [00:43<15:38,  3.06s/it]
  5%|▍         | 15/321 [00:46<15:33,  3.05s/it]
                                                

  5%|▍         | 15/321 [00:46<15:33,  3.05s/it]
  5%|▍         | 16/321 [00:49<14:58,  2.94s/it]
  5%|▌         | 17/321 [00:52<14:50,  2.93s/it]
  6%|▌         | 18/321 [00:55<14:50,  2.94s/it]
  6%|▌         | 19/321 [00:57<14:07,  2.81s/it]
  6%|▌         | 20/321 [01:00<14:36,  2.91s/it]
                                                

  6%|▌         | 20/321 [01:01<14:36,  2.91s/it]
  7%|▋         | 21/321 [01:03<14:40,  2.93s/it]
  7%|▋         | 22/321 [01:06<14:43,  2.95s/it]
  7%|▋         | 23/321 [01:09<14:45,  2.97s/it]
  7%|▋         | 24/321 [01:12<14:25,  2.91s/it]
  8%|▊         | 25/321 [01:15<14:19,  2.90s/it]
                                                

  8%|▊         | 25/321 [01:15<14:19,  2.90s/it]
  8%|▊         | 26/321 [01:17<13:19,  2.71s/it]
  8%|▊         | 27/321 [01:20<13:19,  2.72s/it]
  9%|▊         | 28/321 [01:23<13:40,  2.80s/it]
  9%|▉         | 29/321 [01:27<15:34,  3.20s/it]
  9%|▉         | 30/321 [01:30<15:14,  3.14s/it]
                                                

  9%|▉         | 30/321 [01:30<15:14,  3.14s/it]
 10%|▉         | 31/321 [01:33<14:26,  2.99s/it]
 10%|▉         | 32/321 [01:36<14:38,  3.04s/it]
 10%|█         | 33/321 [01:39<14:30,  3.02s/it]
 11%|█         | 34/321 [01:42<14:53,  3.11s/it]
 11%|█         | 35/321 [01:45<14:47,  3.10s/it]
                                                

 11%|█         | 35/321 [01:46<14:47,  3.10s/it]
 11%|█         | 36/321 [01:48<14:15,  3.00s/it]
 12%|█▏        | 37/321 [01:51<14:11,  3.00s/it]
 12%|█▏        | 38/321 [01:54<14:09,  3.00s/it]
 12%|█▏        | 39/321 [01:57<13:37,  2.90s/it]
 12%|█▏        | 40/321 [02:00<13:28,  2.88s/it]
                                                

 12%|█▏        | 40/321 [02:00<13:28,  2.88s/it]
 13%|█▎        | 41/321 [02:03<13:26,  2.88s/it]
 13%|█▎        | 42/321 [02:06<13:47,  2.96s/it]
 13%|█▎        | 43/321 [02:09<14:37,  3.15s/it]
 14%|█▎        | 44/321 [02:12<13:59,  3.03s/it]
 14%|█▍        | 45/321 [02:15<14:18,  3.11s/it]
                                                

 14%|█▍        | 45/321 [02:15<14:18,  3.11s/it]
 14%|█▍        | 46/321 [02:19<14:36,  3.19s/it]
 15%|█▍        | 47/321 [02:22<14:34,  3.19s/it]
 15%|█▍        | 48/321 [02:25<14:44,  3.24s/it]
 15%|█▌        | 49/321 [02:29<14:47,  3.26s/it]
 16%|█▌        | 50/321 [02:32<14:44,  3.27s/it]
                                                

 16%|█▌        | 50/321 [02:32<14:44,  3.27s/it]
 16%|█▌        | 51/321 [02:35<14:46,  3.28s/it]
 16%|█▌        | 52/321 [02:38<14:10,  3.16s/it]
 17%|█▋        | 53/321 [02:41<13:24,  3.00s/it]
 17%|█▋        | 54/321 [02:44<13:45,  3.09s/it]
 17%|█▋        | 55/321 [02:47<13:20,  3.01s/it]
                                                

 17%|█▋        | 55/321 [02:47<13:20,  3.01s/it]
 17%|█▋        | 56/321 [02:50<13:14,  3.00s/it]
 18%|█▊        | 57/321 [02:53<13:18,  3.02s/it]
 18%|█▊        | 58/321 [02:56<13:56,  3.18s/it]
 18%|█▊        | 59/321 [02:59<13:45,  3.15s/it]
 19%|█▊        | 60/321 [03:03<13:33,  3.12s/it]
                                                

 19%|█▊        | 60/321 [03:03<13:33,  3.12s/it]
 19%|█▉        | 61/321 [03:05<13:18,  3.07s/it]
 19%|█▉        | 62/321 [03:09<13:24,  3.11s/it]
 20%|█▉        | 63/321 [03:12<13:30,  3.14s/it]
 20%|█▉        | 64/321 [03:15<13:02,  3.04s/it]
 20%|██        | 65/321 [03:18<13:00,  3.05s/it]
                                                

 20%|██        | 65/321 [03:18<13:00,  3.05s/it]
 21%|██        | 66/321 [03:21<13:14,  3.12s/it]
 21%|██        | 67/321 [03:24<13:30,  3.19s/it]
 21%|██        | 68/321 [03:27<13:19,  3.16s/it]
 21%|██▏       | 69/321 [03:31<13:34,  3.23s/it]
 22%|██▏       | 70/321 [03:34<13:02,  3.12s/it]
                                                

 22%|██▏       | 70/321 [03:34<13:02,  3.12s/it]
 22%|██▏       | 71/321 [03:37<12:38,  3.03s/it]
 22%|██▏       | 72/321 [03:40<12:45,  3.08s/it]
 23%|██▎       | 73/321 [03:43<12:47,  3.09s/it]
 23%|██▎       | 74/321 [03:46<12:43,  3.09s/it]
 23%|██▎       | 75/321 [03:49<13:02,  3.18s/it]
                                                

 23%|██▎       | 75/321 [03:49<13:02,  3.18s/it]
 24%|██▎       | 76/321 [03:53<13:04,  3.20s/it]
 24%|██▍       | 77/321 [03:55<12:34,  3.09s/it]
 24%|██▍       | 78/321 [03:58<12:18,  3.04s/it]
 25%|██▍       | 79/321 [04:01<12:10,  3.02s/it]
 25%|██▍       | 80/321 [04:05<12:31,  3.12s/it]
                                                

 25%|██▍       | 80/321 [04:05<12:31,  3.12s/it]
 25%|██▌       | 81/321 [04:08<12:13,  3.06s/it]
 26%|██▌       | 82/321 [04:10<11:45,  2.95s/it]
 26%|██▌       | 83/321 [04:14<12:28,  3.15s/it]
 26%|██▌       | 84/321 [04:17<12:02,  3.05s/it]
 26%|██▋       | 85/321 [04:20<12:15,  3.12s/it]
                                                

 26%|██▋       | 85/321 [04:20<12:15,  3.12s/it]
 27%|██▋       | 86/321 [04:23<12:17,  3.14s/it]
 27%|██▋       | 87/321 [04:27<12:29,  3.20s/it]
 27%|██▋       | 88/321 [04:30<12:13,  3.15s/it]
 28%|██▊       | 89/321 [04:32<11:52,  3.07s/it]
 28%|██▊       | 90/321 [04:35<11:22,  2.96s/it]
                                                

 28%|██▊       | 90/321 [04:35<11:22,  2.96s/it]
 28%|██▊       | 91/321 [04:39<12:02,  3.14s/it]
 29%|██▊       | 92/321 [04:42<12:05,  3.17s/it]
 29%|██▉       | 93/321 [04:45<11:42,  3.08s/it]
 29%|██▉       | 94/321 [04:48<11:25,  3.02s/it]
 30%|██▉       | 95/321 [04:51<11:57,  3.18s/it]
                                                

 30%|██▉       | 95/321 [04:51<11:57,  3.18s/it]
 30%|██▉       | 96/321 [04:54<11:36,  3.10s/it]
 30%|███       | 97/321 [04:58<12:25,  3.33s/it]
 31%|███       | 98/321 [05:01<11:53,  3.20s/it]
 31%|███       | 99/321 [05:04<12:00,  3.25s/it]
 31%|███       | 100/321 [05:07<11:24,  3.10s/it]
                                                 

 31%|███       | 100/321 [05:07<11:24,  3.10s/it]
 31%|███▏      | 101/321 [05:10<11:33,  3.15s/it]
 32%|███▏      | 102/321 [05:13<11:08,  3.05s/it]
 32%|███▏      | 103/321 [05:16<11:20,  3.12s/it]
 32%|███▏      | 104/321 [05:19<11:16,  3.12s/it]
 33%|███▎      | 105/321 [05:23<11:12,  3.12s/it]
                                                 

 33%|███▎      | 105/321 [05:23<11:12,  3.12s/it]
 33%|███▎      | 106/321 [05:25<10:51,  3.03s/it]
 33%|███▎      | 107/321 [05:28<10:44,  3.01s/it]Saving model checkpoint to ./sft_models/checkpoint-107
Configuration saved in ./sft_models/checkpoint-107/config.json
Configuration saved in ./sft_models/checkpoint-107/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-107/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-107/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-107/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 34%|███▎      | 108/321 [06:00<40:52, 11.52s/it]
 34%|███▍      | 109/321 [06:03<31:54,  9.03s/it]
 34%|███▍      | 110/321 [06:06<25:35,  7.28s/it]
                                                 

 34%|███▍      | 110/321 [06:06<25:35,  7.28s/it]
 35%|███▍      | 111/321 [06:09<21:16,  6.08s/it]
 35%|███▍      | 112/321 [06:13<18:00,  5.17s/it]
 35%|███▌      | 113/321 [06:15<15:36,  4.50s/it]
 36%|███▌      | 114/321 [06:18<13:52,  4.02s/it]
 36%|███▌      | 115/321 [06:21<12:49,  3.73s/it]
                                                 

 36%|███▌      | 115/321 [06:22<12:49,  3.73s/it]
 36%|███▌      | 116/321 [06:24<11:50,  3.47s/it]
 36%|███▋      | 117/321 [06:27<11:09,  3.28s/it]
 37%|███▋      | 118/321 [06:31<11:27,  3.39s/it]
 37%|███▋      | 119/321 [06:34<11:38,  3.46s/it]
 37%|███▋      | 120/321 [06:38<11:22,  3.39s/it]
                                                 

 37%|███▋      | 120/321 [06:38<11:22,  3.39s/it]
 38%|███▊      | 121/321 [06:40<10:28,  3.14s/it]
 38%|███▊      | 122/321 [06:43<10:15,  3.09s/it]
 38%|███▊      | 123/321 [06:46<10:01,  3.04s/it]
 39%|███▊      | 124/321 [06:49<09:47,  2.98s/it]
 39%|███▉      | 125/321 [06:52<09:55,  3.04s/it]
                                                 

 39%|███▉      | 125/321 [06:52<09:55,  3.04s/it]
 39%|███▉      | 126/321 [06:55<09:38,  2.97s/it]
 40%|███▉      | 127/321 [06:58<09:45,  3.02s/it]
 40%|███▉      | 128/321 [07:01<09:38,  3.00s/it]
 40%|████      | 129/321 [07:04<09:37,  3.01s/it]
 40%|████      | 130/321 [07:07<09:37,  3.02s/it]
                                                 

 40%|████      | 130/321 [07:07<09:37,  3.02s/it]
 41%|████      | 131/321 [07:10<09:30,  3.00s/it]
 41%|████      | 132/321 [07:13<09:19,  2.96s/it]
 41%|████▏     | 133/321 [07:16<09:38,  3.08s/it]
 42%|████▏     | 134/321 [07:19<09:29,  3.04s/it]
 42%|████▏     | 135/321 [07:22<09:29,  3.06s/it]
                                                 

 42%|████▏     | 135/321 [07:22<09:29,  3.06s/it]
 42%|████▏     | 136/321 [07:25<09:04,  2.94s/it]
 43%|████▎     | 137/321 [07:28<09:22,  3.06s/it]
 43%|████▎     | 138/321 [07:31<09:04,  2.97s/it]
 43%|████▎     | 139/321 [07:34<09:00,  2.97s/it]
 44%|████▎     | 140/321 [07:37<09:01,  2.99s/it]
                                                 

 44%|████▎     | 140/321 [07:37<09:01,  2.99s/it]
 44%|████▍     | 141/321 [07:40<09:03,  3.02s/it]
 44%|████▍     | 142/321 [07:43<09:14,  3.10s/it]
 45%|████▍     | 143/321 [07:46<09:01,  3.04s/it]
 45%|████▍     | 144/321 [07:49<09:00,  3.05s/it]
 45%|████▌     | 145/321 [07:53<09:07,  3.11s/it]
                                                 

 45%|████▌     | 145/321 [07:53<09:07,  3.11s/it]
 45%|████▌     | 146/321 [07:56<08:50,  3.03s/it]
 46%|████▌     | 147/321 [07:59<09:07,  3.14s/it]
 46%|████▌     | 148/321 [08:02<08:53,  3.09s/it]
 46%|████▋     | 149/321 [08:05<08:58,  3.13s/it]
 47%|████▋     | 150/321 [08:09<09:23,  3.30s/it]
                                                 

 47%|████▋     | 150/321 [08:09<09:23,  3.30s/it]
 47%|████▋     | 151/321 [08:12<09:41,  3.42s/it]
 47%|████▋     | 152/321 [08:16<09:18,  3.30s/it]
 48%|████▊     | 153/321 [08:19<09:14,  3.30s/it]
 48%|████▊     | 154/321 [08:22<08:49,  3.17s/it]
 48%|████▊     | 155/321 [08:25<08:58,  3.24s/it]
                                                 

 48%|████▊     | 155/321 [08:25<08:58,  3.24s/it]
 49%|████▊     | 156/321 [08:28<08:49,  3.21s/it]
 49%|████▉     | 157/321 [08:31<08:33,  3.13s/it]
 49%|████▉     | 158/321 [08:34<08:17,  3.05s/it]
 50%|████▉     | 159/321 [08:37<08:04,  2.99s/it]
 50%|████▉     | 160/321 [08:40<08:29,  3.16s/it]
                                                 

 50%|████▉     | 160/321 [08:41<08:29,  3.16s/it]
 50%|█████     | 161/321 [08:44<08:40,  3.25s/it]
 50%|█████     | 162/321 [08:47<08:13,  3.10s/it]
 51%|█████     | 163/321 [08:50<08:09,  3.10s/it]
 51%|█████     | 164/321 [08:53<08:09,  3.12s/it]
 51%|█████▏    | 165/321 [08:56<08:12,  3.15s/it]
                                                 

 51%|█████▏    | 165/321 [08:56<08:12,  3.15s/it]
 52%|█████▏    | 166/321 [08:59<07:58,  3.09s/it]
 52%|█████▏    | 167/321 [09:02<08:01,  3.13s/it]
 52%|█████▏    | 168/321 [09:06<08:14,  3.23s/it]
 53%|█████▎    | 169/321 [09:09<08:17,  3.27s/it]
 53%|█████▎    | 170/321 [09:13<08:23,  3.34s/it]
                                                 

 53%|█████▎    | 170/321 [09:13<08:23,  3.34s/it]
 53%|█████▎    | 171/321 [09:16<08:21,  3.35s/it]
 54%|█████▎    | 172/321 [09:19<07:53,  3.18s/it]
 54%|█████▍    | 173/321 [09:21<07:24,  3.00s/it]
 54%|█████▍    | 174/321 [09:24<07:17,  2.97s/it]
 55%|█████▍    | 175/321 [09:27<07:10,  2.95s/it]
                                                 

 55%|█████▍    | 175/321 [09:27<07:10,  2.95s/it]
 55%|█████▍    | 176/321 [09:31<07:24,  3.06s/it]
 55%|█████▌    | 177/321 [09:34<07:22,  3.07s/it]
 55%|█████▌    | 178/321 [09:37<07:24,  3.11s/it]
 56%|█████▌    | 179/321 [09:40<07:29,  3.16s/it]
 56%|█████▌    | 180/321 [09:43<07:18,  3.11s/it]
                                                 

 56%|█████▌    | 180/321 [09:43<07:18,  3.11s/it]
 56%|█████▋    | 181/321 [09:46<07:08,  3.06s/it]
 57%|█████▋    | 182/321 [09:49<07:21,  3.18s/it]
 57%|█████▋    | 183/321 [09:53<07:21,  3.20s/it]
 57%|█████▋    | 184/321 [09:56<07:05,  3.11s/it]
 58%|█████▊    | 185/321 [09:58<06:47,  2.99s/it]
                                                 

 58%|█████▊    | 185/321 [09:59<06:47,  2.99s/it]
 58%|█████▊    | 186/321 [10:01<06:38,  2.95s/it]
 58%|█████▊    | 187/321 [10:04<06:35,  2.95s/it]
 59%|█████▊    | 188/321 [10:07<06:37,  2.99s/it]
 59%|█████▉    | 189/321 [10:10<06:27,  2.93s/it]
 59%|█████▉    | 190/321 [10:13<06:22,  2.92s/it]
                                                 

 59%|█████▉    | 190/321 [10:13<06:22,  2.92s/it]
 60%|█████▉    | 191/321 [10:16<06:12,  2.87s/it]
 60%|█████▉    | 192/321 [10:19<06:17,  2.93s/it]
 60%|██████    | 193/321 [10:22<06:11,  2.90s/it]
 60%|██████    | 194/321 [10:25<06:15,  2.96s/it]
 61%|██████    | 195/321 [10:29<06:54,  3.29s/it]
                                                 

 61%|██████    | 195/321 [10:29<06:54,  3.29s/it]
 61%|██████    | 196/321 [10:32<07:00,  3.37s/it]
 61%|██████▏   | 197/321 [10:36<07:01,  3.40s/it]
 62%|██████▏   | 198/321 [10:39<06:47,  3.31s/it]
 62%|██████▏   | 199/321 [10:42<06:33,  3.23s/it]
 62%|██████▏   | 200/321 [10:45<06:34,  3.26s/it]
                                                 

 62%|██████▏   | 200/321 [10:45<06:34,  3.26s/it]
 63%|██████▎   | 201/321 [10:48<06:21,  3.18s/it]
 63%|██████▎   | 202/321 [10:51<06:04,  3.06s/it]
 63%|██████▎   | 203/321 [10:54<05:58,  3.04s/it]
 64%|██████▎   | 204/321 [10:57<06:05,  3.12s/it]
 64%|██████▍   | 205/321 [11:01<06:05,  3.15s/it]
                                                 

 64%|██████▍   | 205/321 [11:01<06:05,  3.15s/it]
 64%|██████▍   | 206/321 [11:04<06:00,  3.13s/it]
 64%|██████▍   | 207/321 [11:07<05:57,  3.14s/it]
 65%|██████▍   | 208/321 [11:10<05:46,  3.07s/it]
 65%|██████▌   | 209/321 [11:13<05:45,  3.09s/it]
 65%|██████▌   | 210/321 [11:16<05:37,  3.04s/it]
                                                 

 65%|██████▌   | 210/321 [11:16<05:37,  3.04s/it]
 66%|██████▌   | 211/321 [11:19<05:32,  3.02s/it]
 66%|██████▌   | 212/321 [11:22<05:41,  3.13s/it]
 66%|██████▋   | 213/321 [11:25<05:29,  3.05s/it]
 67%|██████▋   | 214/321 [11:28<05:31,  3.10s/it]
 67%|██████▋   | 215/321 [11:31<05:33,  3.15s/it]
                                                 

 67%|██████▋   | 215/321 [11:32<05:33,  3.15s/it]Saving model checkpoint to ./sft_models/checkpoint-215
Configuration saved in ./sft_models/checkpoint-215/config.json
Configuration saved in ./sft_models/checkpoint-215/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-215/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-215/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-215/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 67%|██████▋   | 216/321 [12:11<24:50, 14.19s/it]
 68%|██████▊   | 217/321 [12:14<18:47, 10.84s/it]
 68%|██████▊   | 218/321 [12:17<14:34,  8.49s/it]
 68%|██████▊   | 219/321 [12:20<11:35,  6.82s/it]
 69%|██████▊   | 220/321 [12:23<09:29,  5.63s/it]
                                                 

 69%|██████▊   | 220/321 [12:23<09:29,  5.63s/it]
 69%|██████▉   | 221/321 [12:26<08:03,  4.84s/it]
 69%|██████▉   | 222/321 [12:29<06:55,  4.20s/it]
 69%|██████▉   | 223/321 [12:32<06:10,  3.78s/it]
 70%|██████▉   | 224/321 [12:35<05:56,  3.67s/it]
 70%|███████   | 225/321 [12:38<05:31,  3.46s/it]
                                                 

 70%|███████   | 225/321 [12:38<05:31,  3.46s/it]
 70%|███████   | 226/321 [12:41<05:13,  3.30s/it]
 71%|███████   | 227/321 [12:44<04:57,  3.17s/it]
 71%|███████   | 228/321 [12:47<04:52,  3.15s/it]
 71%|███████▏  | 229/321 [12:50<04:47,  3.12s/it]
 72%|███████▏  | 230/321 [12:53<04:41,  3.10s/it]
                                                 

 72%|███████▏  | 230/321 [12:53<04:41,  3.10s/it]
 72%|███████▏  | 231/321 [12:56<04:40,  3.12s/it]
 72%|███████▏  | 232/321 [13:00<04:46,  3.22s/it]
 73%|███████▎  | 233/321 [13:03<04:55,  3.36s/it]
 73%|███████▎  | 234/321 [13:07<04:52,  3.36s/it]
 73%|███████▎  | 235/321 [13:10<04:57,  3.46s/it]
                                                 

 73%|███████▎  | 235/321 [13:11<04:57,  3.46s/it]
 74%|███████▎  | 236/321 [13:14<04:52,  3.44s/it]
 74%|███████▍  | 237/321 [13:17<04:45,  3.40s/it]
 74%|███████▍  | 238/321 [13:20<04:26,  3.21s/it]
 74%|███████▍  | 239/321 [13:23<04:17,  3.14s/it]
 75%|███████▍  | 240/321 [13:26<04:19,  3.20s/it]
                                                 

 75%|███████▍  | 240/321 [13:26<04:19,  3.20s/it]
 75%|███████▌  | 241/321 [13:29<04:10,  3.14s/it]
 75%|███████▌  | 242/321 [13:32<04:10,  3.17s/it]
 76%|███████▌  | 243/321 [13:35<04:02,  3.10s/it]
 76%|███████▌  | 244/321 [13:38<03:51,  3.00s/it]
 76%|███████▋  | 245/321 [13:41<03:46,  2.97s/it]
                                                 

 76%|███████▋  | 245/321 [13:41<03:46,  2.97s/it]
 77%|███████▋  | 246/321 [13:44<03:45,  3.01s/it]
 77%|███████▋  | 247/321 [13:47<03:40,  2.98s/it]
 77%|███████▋  | 248/321 [13:50<03:34,  2.94s/it]
 78%|███████▊  | 249/321 [13:53<03:36,  3.01s/it]
 78%|███████▊  | 250/321 [13:56<03:39,  3.09s/it]
                                                 

 78%|███████▊  | 250/321 [13:57<03:39,  3.09s/it]
 78%|███████▊  | 251/321 [13:59<03:34,  3.07s/it]
 79%|███████▊  | 252/321 [14:02<03:24,  2.97s/it]
 79%|███████▉  | 253/321 [14:05<03:27,  3.06s/it]
 79%|███████▉  | 254/321 [14:08<03:23,  3.04s/it]
 79%|███████▉  | 255/321 [14:11<03:11,  2.90s/it]
                                                 

 79%|███████▉  | 255/321 [14:11<03:11,  2.90s/it]
 80%|███████▉  | 256/321 [14:14<03:11,  2.94s/it]
 80%|████████  | 257/321 [14:17<03:09,  2.95s/it]
 80%|████████  | 258/321 [14:20<03:08,  2.99s/it]
 81%|████████  | 259/321 [14:23<03:04,  2.98s/it]
 81%|████████  | 260/321 [14:26<03:04,  3.03s/it]
                                                 

 81%|████████  | 260/321 [14:26<03:04,  3.03s/it]
 81%|████████▏ | 261/321 [14:29<03:05,  3.09s/it]
 82%|████████▏ | 262/321 [14:32<03:01,  3.07s/it]
 82%|████████▏ | 263/321 [14:36<02:59,  3.09s/it]
 82%|████████▏ | 264/321 [14:39<02:58,  3.14s/it]
 83%|████████▎ | 265/321 [14:42<03:01,  3.23s/it]
                                                 

 83%|████████▎ | 265/321 [14:42<03:01,  3.23s/it]
 83%|████████▎ | 266/321 [14:45<02:53,  3.16s/it]
 83%|████████▎ | 267/321 [14:48<02:47,  3.11s/it]
 83%|████████▎ | 268/321 [14:52<02:47,  3.16s/it]
 84%|████████▍ | 269/321 [14:54<02:39,  3.06s/it]
 84%|████████▍ | 270/321 [14:57<02:34,  3.03s/it]
                                                 

 84%|████████▍ | 270/321 [14:57<02:34,  3.03s/it]
 84%|████████▍ | 271/321 [15:00<02:31,  3.03s/it]
 85%|████████▍ | 272/321 [15:04<02:34,  3.15s/it]
 85%|████████▌ | 273/321 [15:07<02:26,  3.06s/it]
 85%|████████▌ | 274/321 [15:10<02:29,  3.17s/it]
 86%|████████▌ | 275/321 [15:13<02:20,  3.06s/it]
                                                 

 86%|████████▌ | 275/321 [15:13<02:20,  3.06s/it]
 86%|████████▌ | 276/321 [15:16<02:14,  2.98s/it]
 86%|████████▋ | 277/321 [15:18<02:09,  2.94s/it]
 87%|████████▋ | 278/321 [15:22<02:09,  3.00s/it]
 87%|████████▋ | 279/321 [15:25<02:12,  3.15s/it]
 87%|████████▋ | 280/321 [15:28<02:08,  3.14s/it]
                                                 

 87%|████████▋ | 280/321 [15:28<02:08,  3.14s/it]
 88%|████████▊ | 281/321 [15:32<02:08,  3.21s/it]
 88%|████████▊ | 282/321 [15:35<02:04,  3.18s/it]
 88%|████████▊ | 283/321 [15:38<01:57,  3.10s/it]
 88%|████████▊ | 284/321 [15:40<01:50,  2.99s/it]
 89%|████████▉ | 285/321 [15:44<01:50,  3.07s/it]
                                                 

 89%|████████▉ | 285/321 [15:44<01:50,  3.07s/it]
 89%|████████▉ | 286/321 [15:47<01:45,  3.02s/it]
 89%|████████▉ | 287/321 [15:50<01:43,  3.04s/it]
 90%|████████▉ | 288/321 [15:53<01:40,  3.05s/it]
 90%|█████████ | 289/321 [15:56<01:36,  3.02s/it]
 90%|█████████ | 290/321 [15:59<01:36,  3.11s/it]
                                                 

 90%|█████████ | 290/321 [15:59<01:36,  3.11s/it]
 91%|█████████ | 291/321 [16:03<01:38,  3.28s/it]
 91%|█████████ | 292/321 [16:06<01:34,  3.26s/it]
 91%|█████████▏| 293/321 [16:09<01:33,  3.36s/it]
 92%|█████████▏| 294/321 [16:13<01:28,  3.29s/it]
 92%|█████████▏| 295/321 [16:16<01:24,  3.26s/it]
                                                 

 92%|█████████▏| 295/321 [16:16<01:24,  3.26s/it]
 92%|█████████▏| 296/321 [16:18<01:17,  3.09s/it]
 93%|█████████▎| 297/321 [16:21<01:12,  3.01s/it]
 93%|█████████▎| 298/321 [16:24<01:08,  2.99s/it]
 93%|█████████▎| 299/321 [16:27<01:05,  2.96s/it]
 93%|█████████▎| 300/321 [16:30<01:02,  2.96s/it]
                                                 

 93%|█████████▎| 300/321 [16:30<01:02,  2.96s/it]
 94%|█████████▍| 301/321 [16:33<01:00,  3.03s/it]
 94%|█████████▍| 302/321 [16:37<00:59,  3.13s/it]
 94%|█████████▍| 303/321 [16:39<00:53,  2.95s/it]
 95%|█████████▍| 304/321 [16:42<00:51,  3.04s/it]
 95%|█████████▌| 305/321 [16:45<00:48,  3.05s/it]
                                                 

 95%|█████████▌| 305/321 [16:46<00:48,  3.05s/it]
 95%|█████████▌| 306/321 [16:48<00:45,  3.03s/it]
 96%|█████████▌| 307/321 [16:51<00:41,  2.96s/it]
 96%|█████████▌| 308/321 [16:54<00:39,  3.00s/it]
 96%|█████████▋| 309/321 [16:57<00:36,  3.02s/it]
 97%|█████████▋| 310/321 [17:01<00:35,  3.19s/it]
                                                 

 97%|█████████▋| 310/321 [17:01<00:35,  3.19s/it]
 97%|█████████▋| 311/321 [17:05<00:32,  3.29s/it]
 97%|█████████▋| 312/321 [17:08<00:29,  3.31s/it]
 98%|█████████▊| 313/321 [17:11<00:25,  3.22s/it]
 98%|█████████▊| 314/321 [17:14<00:23,  3.32s/it]
 98%|█████████▊| 315/321 [17:17<00:19,  3.24s/it]
                                                 

 98%|█████████▊| 315/321 [17:18<00:19,  3.24s/it]
 98%|█████████▊| 316/321 [17:20<00:15,  3.10s/it]
 99%|█████████▉| 317/321 [17:23<00:12,  3.05s/it]
 99%|█████████▉| 318/321 [17:26<00:08,  2.99s/it]
 99%|█████████▉| 319/321 [17:29<00:06,  3.02s/it]
100%|█████████▉| 320/321 [17:32<00:03,  3.06s/it]
                                                 

100%|█████████▉| 320/321 [17:32<00:03,  3.06s/it]
100%|██████████| 321/321 [17:36<00:00,  3.22s/it]Saving model checkpoint to ./sft_models/checkpoint-321
Configuration saved in ./sft_models/checkpoint-321/config.json
Configuration saved in ./sft_models/checkpoint-321/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-321/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-321/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-321/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
Saving model checkpoint to ./sft_models/checkpoint-321
Configuration saved in ./sft_models/checkpoint-321/config.json
Configuration saved in ./sft_models/checkpoint-321/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-321/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-321/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-321/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)



                                                 

100%|██████████| 321/321 [19:15<00:00,  3.22s/it]
100%|██████████| 321/321 [19:15<00:00,  3.60s/it]
Waiting for the current checkpoint push to be finished, this might take a couple of minutes.
Saving model checkpoint to ./sft_models
Configuration saved in ./sft_models/config.json
Configuration saved in ./sft_models/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
Saving model checkpoint to ./sft_models
Configuration saved in ./sft_models/config.json
Configuration saved in ./sft_models/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
Configuration saved in ./sft_models/config.json
{'loss': 2.4702, 'grad_norm': 236.0, 'learning_rate': 3.0303030303030305e-06, 'epoch': 0.05}
{'loss': 1.9531, 'grad_norm': 221.0, 'learning_rate': 6.060606060606061e-06, 'epoch': 0.09}
{'loss': 1.3303, 'grad_norm': 5.84375, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.14}
{'loss': 1.072, 'grad_norm': 4.40625, 'learning_rate': 1.2121212121212122e-05, 'epoch': 0.19}
{'loss': 0.9682, 'grad_norm': 4.53125, 'learning_rate': 1.5151515151515153e-05, 'epoch': 0.23}
{'loss': 0.9073, 'grad_norm': 3.90625, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.28}
{'loss': 0.9116, 'grad_norm': 3.65625, 'learning_rate': 1.999762027079909e-05, 'epoch': 0.32}
{'loss': 0.8821, 'grad_norm': 3.921875, 'learning_rate': 1.9970861323044667e-05, 'epoch': 0.37}
{'loss': 0.855, 'grad_norm': 3.234375, 'learning_rate': 1.9914448613738107e-05, 'epoch': 0.42}
{'loss': 0.8404, 'grad_norm': 2.984375, 'learning_rate': 1.9828549916653013e-05, 'epoch': 0.46}
{'loss': 0.8804, 'grad_norm': 3.265625, 'learning_rate': 1.9713420698132614e-05, 'epoch': 0.51}
{'loss': 0.8455, 'grad_norm': 3.109375, 'learning_rate': 1.956940335732209e-05, 'epoch': 0.56}
{'loss': 0.8235, 'grad_norm': 3.09375, 'learning_rate': 1.9396926207859085e-05, 'epoch': 0.6}
{'loss': 0.8288, 'grad_norm': 2.921875, 'learning_rate': 1.9196502204050925e-05, 'epoch': 0.65}
{'loss': 0.8241, 'grad_norm': 3.28125, 'learning_rate': 1.8968727415326885e-05, 'epoch': 0.7}
{'loss': 0.816, 'grad_norm': 2.9375, 'learning_rate': 1.8714279253502616e-05, 'epoch': 0.74}
{'loss': 0.865, 'grad_norm': 3.03125, 'learning_rate': 1.843391445812886e-05, 'epoch': 0.79}
{'loss': 0.8272, 'grad_norm': 2.84375, 'learning_rate': 1.8128466845916156e-05, 'epoch': 0.84}
{'loss': 0.8571, 'grad_norm': 2.875, 'learning_rate': 1.7798844830928818e-05, 'epoch': 0.88}
{'loss': 0.7888, 'grad_norm': 2.78125, 'learning_rate': 1.7446028722923266e-05, 'epoch': 0.93}
{'loss': 0.8245, 'grad_norm': 3.109375, 'learning_rate': 1.7071067811865477e-05, 'epoch': 0.97}
{'loss': 0.7812, 'grad_norm': 2.65625, 'learning_rate': 1.6675077247298475e-05, 'epoch': 1.02}
{'loss': 0.5777, 'grad_norm': 3.046875, 'learning_rate': 1.6259234721840595e-05, 'epoch': 1.07}
{'loss': 0.6002, 'grad_norm': 3.078125, 'learning_rate': 1.5824776968678024e-05, 'epoch': 1.11}
{'loss': 0.6066, 'grad_norm': 3.40625, 'learning_rate': 1.5372996083468242e-05, 'epoch': 1.16}
{'loss': 0.5624, 'grad_norm': 3.203125, 'learning_rate': 1.4905235681593079e-05, 'epoch': 1.21}
{'loss': 0.6039, 'grad_norm': 3.53125, 'learning_rate': 1.4422886902190014e-05, 'epoch': 1.25}
{'loss': 0.5892, 'grad_norm': 3.5625, 'learning_rate': 1.3927384270845744e-05, 'epoch': 1.3}
{'loss': 0.5931, 'grad_norm': 2.859375, 'learning_rate': 1.342020143325669e-05, 'epoch': 1.35}
{'loss': 0.5907, 'grad_norm': 3.359375, 'learning_rate': 1.2902846772544625e-05, 'epoch': 1.39}
{'loss': 0.5559, 'grad_norm': 2.890625, 'learning_rate': 1.2376858923261732e-05, 'epoch': 1.44}
{'loss': 0.59, 'grad_norm': 2.96875, 'learning_rate': 1.1843802195426634e-05, 'epoch': 1.48}
{'loss': 0.5777, 'grad_norm': 3.078125, 'learning_rate': 1.130526192220052e-05, 'epoch': 1.53}
{'loss': 0.5631, 'grad_norm': 3.359375, 'learning_rate': 1.0762839745039526e-05, 'epoch': 1.58}
{'loss': 0.5768, 'grad_norm': 3.15625, 'learning_rate': 1.0218148850345613e-05, 'epoch': 1.62}
{'loss': 0.5726, 'grad_norm': 3.34375, 'learning_rate': 9.67280917178224e-06, 'epoch': 1.67}
{'loss': 0.5503, 'grad_norm': 3.40625, 'learning_rate': 9.128442572523418e-06, 'epoch': 1.72}
{'loss': 0.5714, 'grad_norm': 3.421875, 'learning_rate': 8.586668021764328e-06, 'epoch': 1.76}
{'loss': 0.5718, 'grad_norm': 3.03125, 'learning_rate': 8.04909677983872e-06, 'epoch': 1.81}
{'loss': 0.5492, 'grad_norm': 3.0, 'learning_rate': 7.5173276062628364e-06, 'epoch': 1.86}
{'loss': 0.5686, 'grad_norm': 3.09375, 'learning_rate': 6.992942004957271e-06, 'epoch': 1.9}
{'loss': 0.5834, 'grad_norm': 3.0, 'learning_rate': 6.4774995207876654e-06, 'epoch': 1.95}
{'loss': 0.5856, 'grad_norm': 3.71875, 'learning_rate': 5.97253310141263e-06, 'epoch': 2.0}
{'loss': 0.4838, 'grad_norm': 2.78125, 'learning_rate': 5.479544538232804e-06, 'epoch': 2.04}
{'loss': 0.4045, 'grad_norm': 3.015625, 'learning_rate': 5.000000000000003e-06, 'epoch': 2.09}
{'loss': 0.4158, 'grad_norm': 4.625, 'learning_rate': 4.535325672369567e-06, 'epoch': 2.13}
{'loss': 0.3978, 'grad_norm': 4.53125, 'learning_rate': 4.086903516364179e-06, 'epoch': 2.18}
{'loss': 0.3932, 'grad_norm': 3.5625, 'learning_rate': 3.6560671583635467e-06, 'epoch': 2.23}
{'loss': 0.4042, 'grad_norm': 3.828125, 'learning_rate': 3.2440979238433977e-06, 'epoch': 2.27}
{'loss': 0.4016, 'grad_norm': 3.390625, 'learning_rate': 2.8522210266595386e-06, 'epoch': 2.32}
{'loss': 0.4279, 'grad_norm': 3.984375, 'learning_rate': 2.4816019252102274e-06, 'epoch': 2.37}
{'loss': 0.3948, 'grad_norm': 3.265625, 'learning_rate': 2.1333428563138304e-06, 'epoch': 2.41}
{'loss': 0.3991, 'grad_norm': 3.796875, 'learning_rate': 1.808479557110081e-06, 'epoch': 2.46}
{'loss': 0.4063, 'grad_norm': 3.640625, 'learning_rate': 1.5079781847342122e-06, 'epoch': 2.51}
{'loss': 0.3833, 'grad_norm': 3.1875, 'learning_rate': 1.2327324429249232e-06, 'epoch': 2.55}
{'loss': 0.3967, 'grad_norm': 3.5, 'learning_rate': 9.835609241118404e-07, 'epoch': 2.6}
{'loss': 0.3974, 'grad_norm': 3.984375, 'learning_rate': 7.612046748871327e-07, 'epoch': 2.65}
{'loss': 0.4124, 'grad_norm': 3.90625, 'learning_rate': 5.663249921017477e-07, 'epoch': 2.69}
{'loss': 0.379, 'grad_norm': 3.71875, 'learning_rate': 3.99501456140714e-07, 'epoch': 2.74}
{'loss': 0.397, 'grad_norm': 3.53125, 'learning_rate': 2.612302072266637e-07, 'epoch': 2.78}
{'loss': 0.4047, 'grad_norm': 3.40625, 'learning_rate': 1.519224698779198e-07, 'epoch': 2.83}
{'loss': 0.4339, 'grad_norm': 3.203125, 'learning_rate': 7.19033299094496e-08, 'epoch': 2.88}
{'loss': 0.3927, 'grad_norm': 3.546875, 'learning_rate': 2.1410767613965212e-08, 'epoch': 2.92}
{'loss': 0.3904, 'grad_norm': 3.453125, 'learning_rate': 5.949499985025142e-10, 'epoch': 2.97}
{'train_runtime': 1156.2716, 'train_samples_per_second': 8.946, 'train_steps_per_second': 0.278, 'train_loss': 0.6682053277054308, 'epoch': 2.98}
***** train metrics *****
  epoch                    =     2.9791
  total_flos               = 30372626GF
  train_loss               =     0.6682
  train_runtime            = 0:19:16.27
  train_samples            =       3448
  train_samples_per_second =      8.946
  train_steps_per_second   =      0.278
Model saved to ./sft_models
[1;34mwandb[0m: 🚀 View run [33m./sft_models[0m at: [34mhttps://wandb.ai/yutongyin/huggingface/runs/rmxsrdag[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241113_023157-rmxsrdag/logs[0m
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': model_init_kwargs, max_seq_length. Will not be supported from version '0.13.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:175: UserWarning: You passed `model_init_kwargs` to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:202: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
--- Logging error ---
Traceback (most recent call last):
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 1110, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 953, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 687, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 377, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 153, in <module>
    trainer = SFTTrainer(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py", line 209, in __init__
    model = AutoModelForCausalLM.from_pretrained(model, **model_init_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4097, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 963, in __init__
    super().__init__(config)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 1432, in __init__
    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1235, in from_model_config
    generation_config = cls.from_dict(config_dict, return_unused_kwargs=False, _from_model_config=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1093, in from_dict
    config = cls(**{**config_dict, **kwargs})
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 475, in __init__
    self.validate(is_init=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 751, in validate
    logger.warning_once(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/logging.py", line 328, in warning_once
    self.warning(*args, **kwargs)
Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'
Arguments: (<class 'UserWarning'>,)

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.97it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.35it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.09it/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.
  warnings.warn(
[2024-11-13 03:27:30,408] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using auto half precision backend
***** Running training *****
  Num examples = 3,448
  Num Epochs = 6
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 4
  Total optimization steps = 642
  Number of trainable parameters = 2,614,341,888
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yutongyin2028 (yutongyin). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/cyc2202/LLM-as-Latent-Variable-Model/wandb/run-20241113_032731-wg0r8q9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma2-2b-restem
wandb: ⭐️ View project at https://wandb.ai/yutongyin/huggingface
wandb: 🚀 View run at https://wandb.ai/yutongyin/huggingface/runs/wg0r8q9q

  0%|          | 0/642 [00:00<?, ?it/s]/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

  0%|          | 1/642 [00:03<34:15,  3.21s/it]
  0%|          | 2/642 [00:06<32:32,  3.05s/it]
  0%|          | 3/642 [00:09<32:54,  3.09s/it]
  1%|          | 4/642 [00:12<32:08,  3.02s/it]
  1%|          | 5/642 [00:15<31:46,  2.99s/it]
                                               

  1%|          | 5/642 [00:15<31:46,  2.99s/it]
  1%|          | 6/642 [00:18<32:25,  3.06s/it]
  1%|          | 7/642 [00:22<34:37,  3.27s/it]
  1%|          | 8/642 [00:24<32:54,  3.11s/it]
  1%|▏         | 9/642 [00:27<32:18,  3.06s/it]
  2%|▏         | 10/642 [00:31<32:50,  3.12s/it]
                                                

  2%|▏         | 10/642 [00:31<32:50,  3.12s/it]
  2%|▏         | 11/642 [00:34<32:41,  3.11s/it]
  2%|▏         | 12/642 [00:37<32:43,  3.12s/it]
  2%|▏         | 13/642 [00:39<31:07,  2.97s/it]
  2%|▏         | 14/642 [00:43<32:05,  3.07s/it]
  2%|▏         | 15/642 [00:46<32:01,  3.06s/it]
                                                

  2%|▏         | 15/642 [00:46<32:01,  3.06s/it]
  2%|▏         | 16/642 [00:48<30:50,  2.96s/it]
  3%|▎         | 17/642 [00:51<30:37,  2.94s/it]
  3%|▎         | 18/642 [00:54<30:43,  2.95s/it]
  3%|▎         | 19/642 [00:57<29:17,  2.82s/it]
  3%|▎         | 20/642 [01:00<30:22,  2.93s/it]
                                                

  3%|▎         | 20/642 [01:00<30:22,  2.93s/it]
  3%|▎         | 21/642 [01:03<30:31,  2.95s/it]
  3%|▎         | 22/642 [01:06<30:40,  2.97s/it]
  4%|▎         | 23/642 [01:09<30:49,  2.99s/it]
  4%|▎         | 24/642 [01:12<30:09,  2.93s/it]
  4%|▍         | 25/642 [01:15<29:59,  2.92s/it]
                                                

  4%|▍         | 25/642 [01:15<29:59,  2.92s/it]
  4%|▍         | 26/642 [01:17<27:55,  2.72s/it]
  4%|▍         | 27/642 [01:20<27:59,  2.73s/it]
  4%|▍         | 28/642 [01:23<28:47,  2.81s/it]
  5%|▍         | 29/642 [01:27<32:49,  3.21s/it]
  5%|▍         | 30/642 [01:30<32:10,  3.15s/it]
                                                

  5%|▍         | 30/642 [01:30<32:10,  3.15s/it]
  5%|▍         | 31/642 [01:33<30:32,  3.00s/it]
  5%|▍         | 32/642 [01:36<31:00,  3.05s/it]
  5%|▌         | 33/642 [01:39<30:48,  3.03s/it]
  5%|▌         | 34/642 [01:42<31:38,  3.12s/it]
  5%|▌         | 35/642 [01:45<31:29,  3.11s/it]
                                                

  5%|▌         | 35/642 [01:45<31:29,  3.11s/it]
  6%|▌         | 36/642 [01:48<30:23,  3.01s/it]
  6%|▌         | 37/642 [01:51<30:16,  3.00s/it]
  6%|▌         | 38/642 [01:54<30:16,  3.01s/it]
  6%|▌         | 39/642 [01:57<29:12,  2.91s/it]
  6%|▌         | 40/642 [01:59<28:56,  2.88s/it]
                                                

  6%|▌         | 40/642 [02:00<28:56,  2.88s/it]
  6%|▋         | 41/642 [02:02<28:54,  2.89s/it]
  7%|▋         | 42/642 [02:05<29:42,  2.97s/it]
  7%|▋         | 43/642 [02:09<31:33,  3.16s/it]
  7%|▋         | 44/642 [02:12<30:16,  3.04s/it]
  7%|▋         | 45/642 [02:15<31:00,  3.12s/it]
                                                

  7%|▋         | 45/642 [02:15<31:00,  3.12s/it]
  7%|▋         | 46/642 [02:18<31:44,  3.20s/it]
  7%|▋         | 47/642 [02:22<31:43,  3.20s/it]
  7%|▋         | 48/642 [02:25<32:07,  3.25s/it]
  8%|▊         | 49/642 [02:28<32:18,  3.27s/it]
  8%|▊         | 50/642 [02:32<32:14,  3.27s/it]
                                                

  8%|▊         | 50/642 [02:32<32:14,  3.27s/it]
  8%|▊         | 51/642 [02:35<32:20,  3.28s/it]
  8%|▊         | 52/642 [02:38<31:07,  3.16s/it]
  8%|▊         | 53/642 [02:40<29:30,  3.01s/it]
  8%|▊         | 54/642 [02:44<30:21,  3.10s/it]
  9%|▊         | 55/642 [02:47<29:28,  3.01s/it]
                                                

  9%|▊         | 55/642 [02:47<29:28,  3.01s/it]
  9%|▊         | 56/642 [02:50<29:19,  3.00s/it]
  9%|▉         | 57/642 [02:53<29:31,  3.03s/it]
  9%|▉         | 58/642 [02:56<30:59,  3.18s/it]
  9%|▉         | 59/642 [02:59<30:38,  3.15s/it]
  9%|▉         | 60/642 [03:02<30:16,  3.12s/it]
                                                

  9%|▉         | 60/642 [03:03<30:16,  3.12s/it]
 10%|▉         | 61/642 [03:05<29:44,  3.07s/it]
 10%|▉         | 62/642 [03:09<30:02,  3.11s/it]
 10%|▉         | 63/642 [03:12<30:17,  3.14s/it]
 10%|▉         | 64/642 [03:15<29:19,  3.04s/it]
 10%|█         | 65/642 [03:18<29:18,  3.05s/it]
                                                

 10%|█         | 65/642 [03:18<29:18,  3.05s/it]
 10%|█         | 66/642 [03:21<29:53,  3.11s/it]
 10%|█         | 67/642 [03:24<30:31,  3.19s/it]
 11%|█         | 68/642 [03:27<30:11,  3.16s/it]
 11%|█         | 69/642 [03:31<30:49,  3.23s/it]
 11%|█         | 70/642 [03:34<29:41,  3.12s/it]
                                                

 11%|█         | 70/642 [03:34<29:41,  3.12s/it]
 11%|█         | 71/642 [03:36<28:51,  3.03s/it]
 11%|█         | 72/642 [03:40<29:13,  3.08s/it]
 11%|█▏        | 73/642 [03:43<29:20,  3.09s/it]
 12%|█▏        | 74/642 [03:46<29:13,  3.09s/it]
 12%|█▏        | 75/642 [03:49<30:04,  3.18s/it]
                                                

 12%|█▏        | 75/642 [03:49<30:04,  3.18s/it]
 12%|█▏        | 76/642 [03:52<30:12,  3.20s/it]
 12%|█▏        | 77/642 [03:55<29:06,  3.09s/it]
 12%|█▏        | 78/642 [03:58<28:33,  3.04s/it]
 12%|█▏        | 79/642 [04:01<28:17,  3.02s/it]
 12%|█▏        | 80/642 [04:04<29:10,  3.12s/it]
                                                

 12%|█▏        | 80/642 [04:05<29:10,  3.12s/it]
 13%|█▎        | 81/642 [04:07<28:33,  3.05s/it]
 13%|█▎        | 82/642 [04:10<27:32,  2.95s/it]
 13%|█▎        | 83/642 [04:14<29:17,  3.14s/it]
 13%|█▎        | 84/642 [04:17<28:20,  3.05s/it]
 13%|█▎        | 85/642 [04:20<28:53,  3.11s/it]
                                                

 13%|█▎        | 85/642 [04:20<28:53,  3.11s/it]
 13%|█▎        | 86/642 [04:23<29:02,  3.13s/it]
 14%|█▎        | 87/642 [04:26<29:33,  3.20s/it]
 14%|█▎        | 88/642 [04:29<29:00,  3.14s/it]
 14%|█▍        | 89/642 [04:32<28:13,  3.06s/it]
 14%|█▍        | 90/642 [04:35<27:08,  2.95s/it]
                                                

 14%|█▍        | 90/642 [04:35<27:08,  2.95s/it]
 14%|█▍        | 91/642 [04:38<28:47,  3.13s/it]
 14%|█▍        | 92/642 [04:42<29:00,  3.16s/it]
 14%|█▍        | 93/642 [04:45<28:08,  3.08s/it]
 15%|█▍        | 94/642 [04:47<27:31,  3.01s/it]
 15%|█▍        | 95/642 [04:51<28:54,  3.17s/it]
                                                

 15%|█▍        | 95/642 [04:51<28:54,  3.17s/it]
 15%|█▍        | 96/642 [04:54<28:09,  3.10s/it]
 15%|█▌        | 97/642 [04:58<30:14,  3.33s/it]
 15%|█▌        | 98/642 [05:01<29:00,  3.20s/it]
 15%|█▌        | 99/642 [05:04<29:20,  3.24s/it]
 16%|█▌        | 100/642 [05:07<27:57,  3.09s/it]
                                                 

 16%|█▌        | 100/642 [05:07<27:57,  3.09s/it]
 16%|█▌        | 101/642 [05:10<28:24,  3.15s/it]
 16%|█▌        | 102/642 [05:13<27:28,  3.05s/it]
 16%|█▌        | 103/642 [05:16<28:01,  3.12s/it]
 16%|█▌        | 104/642 [05:19<27:53,  3.11s/it]
 16%|█▋        | 105/642 [05:22<27:49,  3.11s/it]
                                                 

 16%|█▋        | 105/642 [05:22<27:49,  3.11s/it]
 17%|█▋        | 106/642 [05:25<27:01,  3.03s/it]
 17%|█▋        | 107/642 [05:28<26:48,  3.01s/it]Saving model checkpoint to ./sft_models/checkpoint-107
Configuration saved in ./sft_models/checkpoint-107/config.json
Configuration saved in ./sft_models/checkpoint-107/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-107/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-107/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-107/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 17%|█▋        | 108/642 [06:41<3:34:21, 24.09s/it]
 17%|█▋        | 109/642 [06:45<2:38:19, 17.82s/it]
 17%|█▋        | 110/642 [06:48<1:59:04, 13.43s/it]
                                                   

 17%|█▋        | 110/642 [06:48<1:59:04, 13.43s/it]
 17%|█▋        | 111/642 [06:51<1:31:54, 10.39s/it]
 17%|█▋        | 112/642 [06:54<1:12:14,  8.18s/it]
 18%|█▊        | 113/642 [06:57<58:13,  6.60s/it]  
 18%|█▊        | 114/642 [07:00<48:15,  5.48s/it]
 18%|█▊        | 115/642 [07:03<41:45,  4.75s/it]
                                                 

 18%|█▊        | 115/642 [07:03<41:45,  4.75s/it]
 18%|█▊        | 116/642 [07:06<36:35,  4.17s/it]
 18%|█▊        | 117/642 [07:09<33:01,  3.77s/it]
 18%|█▊        | 118/642 [07:12<32:58,  3.78s/it]
 19%|█▊        | 119/642 [07:16<32:27,  3.72s/it]
 19%|█▊        | 120/642 [07:19<31:07,  3.58s/it]
                                                 

 19%|█▊        | 120/642 [07:19<31:07,  3.58s/it]
 19%|█▉        | 121/642 [07:22<28:23,  3.27s/it]
 19%|█▉        | 122/642 [07:25<27:31,  3.18s/it]
 19%|█▉        | 123/642 [07:28<26:45,  3.09s/it]
 19%|█▉        | 124/642 [07:30<26:03,  3.02s/it]
 19%|█▉        | 125/642 [07:34<26:22,  3.06s/it]
                                                 

 19%|█▉        | 125/642 [07:34<26:22,  3.06s/it]
 20%|█▉        | 126/642 [07:36<25:40,  2.99s/it]
 20%|█▉        | 127/642 [07:40<25:59,  3.03s/it]
 20%|█▉        | 128/642 [07:43<26:13,  3.06s/it]
 20%|██        | 129/642 [07:46<25:48,  3.02s/it]
 20%|██        | 130/642 [07:49<25:50,  3.03s/it]
                                                 

 20%|██        | 130/642 [07:49<25:50,  3.03s/it]
 20%|██        | 131/642 [07:52<25:36,  3.01s/it]
 21%|██        | 132/642 [07:54<25:11,  2.96s/it]
 21%|██        | 133/642 [07:58<26:07,  3.08s/it]
 21%|██        | 134/642 [08:01<25:46,  3.04s/it]
 21%|██        | 135/642 [08:04<25:53,  3.06s/it]
                                                 

 21%|██        | 135/642 [08:04<25:53,  3.06s/it]
 21%|██        | 136/642 [08:07<24:51,  2.95s/it]
 21%|██▏       | 137/642 [08:10<25:46,  3.06s/it]
 21%|██▏       | 138/642 [08:13<25:00,  2.98s/it]
 22%|██▏       | 139/642 [08:16<25:27,  3.04s/it]
 22%|██▏       | 140/642 [08:19<25:25,  3.04s/it]
                                                 

 22%|██▏       | 140/642 [08:19<25:25,  3.04s/it]
 22%|██▏       | 141/642 [08:22<25:29,  3.05s/it]
 22%|██▏       | 142/642 [08:25<26:00,  3.12s/it]
 22%|██▏       | 143/642 [08:28<25:27,  3.06s/it]
 22%|██▏       | 144/642 [08:31<25:25,  3.06s/it]
 23%|██▎       | 145/642 [08:35<25:50,  3.12s/it]
                                                 

 23%|██▎       | 145/642 [08:35<25:50,  3.12s/it]
 23%|██▎       | 146/642 [08:37<25:06,  3.04s/it]
 23%|██▎       | 147/642 [08:41<25:56,  3.14s/it]
 23%|██▎       | 148/642 [08:44<25:22,  3.08s/it]
 23%|██▎       | 149/642 [08:47<25:38,  3.12s/it]
 23%|██▎       | 150/642 [08:50<26:28,  3.23s/it]
                                                 

 23%|██▎       | 150/642 [08:51<26:28,  3.23s/it]
 24%|██▎       | 151/642 [08:54<27:35,  3.37s/it]
 24%|██▎       | 152/642 [08:57<26:40,  3.27s/it]
 24%|██▍       | 153/642 [09:00<26:40,  3.27s/it]
 24%|██▍       | 154/642 [09:03<25:37,  3.15s/it]
 24%|██▍       | 155/642 [09:07<26:10,  3.22s/it]
                                                 

 24%|██▍       | 155/642 [09:07<26:10,  3.22s/it]
 24%|██▍       | 156/642 [09:10<25:53,  3.20s/it]
 24%|██▍       | 157/642 [09:13<25:11,  3.12s/it]
 25%|██▍       | 158/642 [09:16<24:33,  3.04s/it]
 25%|██▍       | 159/642 [09:18<23:59,  2.98s/it]
 25%|██▍       | 160/642 [09:22<24:44,  3.08s/it]
                                                 

 25%|██▍       | 160/642 [09:22<24:44,  3.08s/it]
 25%|██▌       | 161/642 [09:25<26:10,  3.27s/it]
 25%|██▌       | 162/642 [09:28<24:53,  3.11s/it]
 25%|██▌       | 163/642 [09:31<24:45,  3.10s/it]
 26%|██▌       | 164/642 [09:34<24:51,  3.12s/it]
 26%|██▌       | 165/642 [09:38<25:04,  3.15s/it]
                                                 

 26%|██▌       | 165/642 [09:38<25:04,  3.15s/it]
 26%|██▌       | 166/642 [09:41<24:29,  3.09s/it]
 26%|██▌       | 167/642 [09:44<24:43,  3.12s/it]
 26%|██▌       | 168/642 [09:47<25:29,  3.23s/it]
 26%|██▋       | 169/642 [09:51<25:44,  3.26s/it]
 26%|██▋       | 170/642 [09:54<26:10,  3.33s/it]
                                                 

 26%|██▋       | 170/642 [09:54<26:10,  3.33s/it]
 27%|██▋       | 171/642 [09:57<26:07,  3.33s/it]
 27%|██▋       | 172/642 [10:00<24:48,  3.17s/it]
 27%|██▋       | 173/642 [10:03<23:22,  2.99s/it]
 27%|██▋       | 174/642 [10:06<23:08,  2.97s/it]
 27%|██▋       | 175/642 [10:09<22:54,  2.94s/it]
                                                 

 27%|██▋       | 175/642 [10:09<22:54,  2.94s/it]
 27%|██▋       | 176/642 [10:12<23:44,  3.06s/it]
 28%|██▊       | 177/642 [10:15<23:45,  3.07s/it]
 28%|██▊       | 178/642 [10:18<23:59,  3.10s/it]
 28%|██▊       | 179/642 [10:21<24:21,  3.16s/it]
 28%|██▊       | 180/642 [10:24<23:51,  3.10s/it]
                                                 

 28%|██▊       | 180/642 [10:25<23:51,  3.10s/it]
 28%|██▊       | 181/642 [10:27<23:27,  3.05s/it]
 28%|██▊       | 182/642 [10:31<23:48,  3.11s/it]
 29%|██▊       | 183/642 [10:34<24:29,  3.20s/it]
 29%|██▊       | 184/642 [10:37<23:43,  3.11s/it]
 29%|██▉       | 185/642 [10:40<22:48,  3.00s/it]
                                                 

 29%|██▉       | 185/642 [10:40<22:48,  3.00s/it]
 29%|██▉       | 186/642 [10:43<22:24,  2.95s/it]
 29%|██▉       | 187/642 [10:45<22:22,  2.95s/it]
 29%|██▉       | 188/642 [10:49<22:35,  2.99s/it]
 29%|██▉       | 189/642 [10:51<22:07,  2.93s/it]
 30%|██▉       | 190/642 [10:54<21:57,  2.91s/it]
                                                 

 30%|██▉       | 190/642 [10:54<21:57,  2.91s/it]
 30%|██▉       | 191/642 [10:57<21:30,  2.86s/it]
 30%|██▉       | 192/642 [11:00<21:55,  2.92s/it]
 30%|███       | 193/642 [11:03<21:55,  2.93s/it]
 30%|███       | 194/642 [11:06<22:13,  2.98s/it]
 30%|███       | 195/642 [11:10<24:37,  3.30s/it]
                                                 

 30%|███       | 195/642 [11:10<24:37,  3.30s/it]
 31%|███       | 196/642 [11:14<25:05,  3.38s/it]
 31%|███       | 197/642 [11:17<25:17,  3.41s/it]
 31%|███       | 198/642 [11:20<24:34,  3.32s/it]
 31%|███       | 199/642 [11:23<23:51,  3.23s/it]
 31%|███       | 200/642 [11:27<24:03,  3.27s/it]
                                                 

 31%|███       | 200/642 [11:27<24:03,  3.27s/it]
 31%|███▏      | 201/642 [11:30<23:25,  3.19s/it]
 31%|███▏      | 202/642 [11:32<22:28,  3.06s/it]
 32%|███▏      | 203/642 [11:35<21:48,  2.98s/it]
 32%|███▏      | 204/642 [11:39<22:47,  3.12s/it]
 32%|███▏      | 205/642 [11:42<22:57,  3.15s/it]
                                                 

 32%|███▏      | 205/642 [11:42<22:57,  3.15s/it]
 32%|███▏      | 206/642 [11:45<22:47,  3.14s/it]
 32%|███▏      | 207/642 [11:48<22:45,  3.14s/it]
 32%|███▏      | 208/642 [11:51<22:11,  3.07s/it]
 33%|███▎      | 209/642 [11:54<22:17,  3.09s/it]
 33%|███▎      | 210/642 [11:57<21:54,  3.04s/it]
                                                 

 33%|███▎      | 210/642 [11:57<21:54,  3.04s/it]
 33%|███▎      | 211/642 [12:00<21:44,  3.03s/it]
 33%|███▎      | 212/642 [12:03<22:26,  3.13s/it]
 33%|███▎      | 213/642 [12:06<21:47,  3.05s/it]
 33%|███▎      | 214/642 [12:10<22:04,  3.10s/it]
 33%|███▎      | 215/642 [12:13<22:19,  3.14s/it]
                                                 

 33%|███▎      | 215/642 [12:13<22:19,  3.14s/it]Saving model checkpoint to ./sft_models/checkpoint-215
Configuration saved in ./sft_models/checkpoint-215/config.json
Configuration saved in ./sft_models/checkpoint-215/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-215/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-215/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-215/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 34%|███▎      | 216/642 [13:18<2:35:11, 21.86s/it]
 34%|███▍      | 217/642 [13:21<1:54:47, 16.21s/it]
 34%|███▍      | 218/642 [13:24<1:26:30, 12.24s/it]
 34%|███▍      | 219/642 [13:27<1:06:34,  9.44s/it]
 34%|███▍      | 220/642 [13:30<52:31,  7.47s/it]  
                                                 

 34%|███▍      | 220/642 [13:30<52:31,  7.47s/it]
 34%|███▍      | 221/642 [13:33<42:53,  6.11s/it]
 35%|███▍      | 222/642 [13:36<35:37,  5.09s/it]
 35%|███▍      | 223/642 [13:39<30:43,  4.40s/it]
 35%|███▍      | 224/642 [13:42<28:05,  4.03s/it]
 35%|███▌      | 225/642 [13:45<26:00,  3.74s/it]
                                                 

 35%|███▌      | 225/642 [13:45<26:00,  3.74s/it]
 35%|███▌      | 226/642 [13:48<24:16,  3.50s/it]
 35%|███▌      | 227/642 [13:51<22:51,  3.30s/it]
 36%|███▌      | 228/642 [13:54<22:22,  3.24s/it]
 36%|███▌      | 229/642 [13:57<21:57,  3.19s/it]
 36%|███▌      | 230/642 [14:00<21:35,  3.14s/it]
                                                 

 36%|███▌      | 230/642 [14:00<21:35,  3.14s/it]
 36%|███▌      | 231/642 [14:03<21:33,  3.15s/it]
 36%|███▌      | 232/642 [14:06<22:08,  3.24s/it]
 36%|███▋      | 233/642 [14:10<22:58,  3.37s/it]
 36%|███▋      | 234/642 [14:13<22:52,  3.36s/it]
 37%|███▋      | 235/642 [14:17<23:29,  3.46s/it]
                                                 

 37%|███▋      | 235/642 [14:17<23:29,  3.46s/it]
 37%|███▋      | 236/642 [14:20<23:17,  3.44s/it]
 37%|███▋      | 237/642 [14:24<22:56,  3.40s/it]
 37%|███▋      | 238/642 [14:27<21:35,  3.21s/it]
 37%|███▋      | 239/642 [14:29<21:04,  3.14s/it]
 37%|███▋      | 240/642 [14:33<21:25,  3.20s/it]
                                                 

 37%|███▋      | 240/642 [14:33<21:25,  3.20s/it]
 38%|███▊      | 241/642 [14:36<20:55,  3.13s/it]
 38%|███▊      | 242/642 [14:39<21:05,  3.16s/it]
 38%|███▊      | 243/642 [14:42<20:36,  3.10s/it]
 38%|███▊      | 244/642 [14:45<19:54,  3.00s/it]
 38%|███▊      | 245/642 [14:48<19:39,  2.97s/it]
                                                 

 38%|███▊      | 245/642 [14:48<19:39,  2.97s/it]
 38%|███▊      | 246/642 [14:51<19:48,  3.00s/it]
 38%|███▊      | 247/642 [14:54<19:36,  2.98s/it]
 39%|███▊      | 248/642 [14:57<19:17,  2.94s/it]
 39%|███▉      | 249/642 [15:00<19:39,  3.00s/it]
 39%|███▉      | 250/642 [15:03<20:10,  3.09s/it]
                                                 

 39%|███▉      | 250/642 [15:03<20:10,  3.09s/it]
 39%|███▉      | 251/642 [15:06<19:58,  3.07s/it]
 39%|███▉      | 252/642 [15:09<19:17,  2.97s/it]
 39%|███▉      | 253/642 [15:12<19:46,  3.05s/it]
 40%|███▉      | 254/642 [15:15<19:38,  3.04s/it]
 40%|███▉      | 255/642 [15:18<18:40,  2.90s/it]
                                                 

 40%|███▉      | 255/642 [15:18<18:40,  2.90s/it]
 40%|███▉      | 256/642 [15:21<18:48,  2.92s/it]
 40%|████      | 257/642 [15:23<18:52,  2.94s/it]
 40%|████      | 258/642 [15:27<19:05,  2.98s/it]
 40%|████      | 259/642 [15:30<18:59,  2.97s/it]
 40%|████      | 260/642 [15:33<19:14,  3.02s/it]
                                                 

 40%|████      | 260/642 [15:33<19:14,  3.02s/it]
 41%|████      | 261/642 [15:36<19:37,  3.09s/it]
 41%|████      | 262/642 [15:39<19:25,  3.07s/it]
 41%|████      | 263/642 [15:42<19:30,  3.09s/it]
 41%|████      | 264/642 [15:45<19:44,  3.13s/it]
 41%|████▏     | 265/642 [15:49<20:18,  3.23s/it]
                                                 

 41%|████▏     | 265/642 [15:49<20:18,  3.23s/it]
 41%|████▏     | 266/642 [15:52<19:48,  3.16s/it]
 42%|████▏     | 267/642 [15:55<19:25,  3.11s/it]
 42%|████▏     | 268/642 [15:58<19:42,  3.16s/it]
 42%|████▏     | 269/642 [16:01<19:02,  3.06s/it]
 42%|████▏     | 270/642 [16:04<18:49,  3.04s/it]
                                                 

 42%|████▏     | 270/642 [16:04<18:49,  3.04s/it]
 42%|████▏     | 271/642 [16:07<18:45,  3.03s/it]
 42%|████▏     | 272/642 [16:10<19:25,  3.15s/it]
 43%|████▎     | 273/642 [16:13<18:51,  3.07s/it]
 43%|████▎     | 274/642 [16:17<19:28,  3.17s/it]
 43%|████▎     | 275/642 [16:19<18:42,  3.06s/it]
                                                 

 43%|████▎     | 275/642 [16:20<18:42,  3.06s/it]
 43%|████▎     | 276/642 [16:22<18:11,  2.98s/it]
 43%|████▎     | 277/642 [16:25<17:52,  2.94s/it]
 43%|████▎     | 278/642 [16:28<18:11,  3.00s/it]
 43%|████▎     | 279/642 [16:32<19:00,  3.14s/it]
 44%|████▎     | 280/642 [16:35<18:52,  3.13s/it]
                                                 

 44%|████▎     | 280/642 [16:35<18:52,  3.13s/it]
 44%|████▍     | 281/642 [16:38<19:17,  3.21s/it]
 44%|████▍     | 282/642 [16:41<19:03,  3.18s/it]
 44%|████▍     | 283/642 [16:44<18:31,  3.10s/it]
 44%|████▍     | 284/642 [16:47<17:48,  2.99s/it]
 44%|████▍     | 285/642 [16:50<18:14,  3.07s/it]
                                                 

 44%|████▍     | 285/642 [16:50<18:14,  3.07s/it]
 45%|████▍     | 286/642 [16:53<17:53,  3.02s/it]
 45%|████▍     | 287/642 [16:56<17:58,  3.04s/it]
 45%|████▍     | 288/642 [16:59<17:58,  3.05s/it]
 45%|████▌     | 289/642 [17:02<17:44,  3.01s/it]
 45%|████▌     | 290/642 [17:05<18:05,  3.08s/it]
                                                 

 45%|████▌     | 290/642 [17:05<18:05,  3.08s/it]
 45%|████▌     | 291/642 [17:09<19:05,  3.26s/it]
 45%|████▌     | 292/642 [17:12<18:57,  3.25s/it]
 46%|████▌     | 293/642 [17:16<19:28,  3.35s/it]
 46%|████▌     | 294/642 [17:19<19:04,  3.29s/it]
 46%|████▌     | 295/642 [17:22<18:50,  3.26s/it]
                                                 

 46%|████▌     | 295/642 [17:22<18:50,  3.26s/it]
 46%|████▌     | 296/642 [17:25<17:48,  3.09s/it]
 46%|████▋     | 297/642 [17:28<17:18,  3.01s/it]
 46%|████▋     | 298/642 [17:31<17:08,  2.99s/it]
 47%|████▋     | 299/642 [17:33<16:53,  2.95s/it]
 47%|████▋     | 300/642 [17:36<16:53,  2.96s/it]
                                                 

 47%|████▋     | 300/642 [17:37<16:53,  2.96s/it]
 47%|████▋     | 301/642 [17:40<17:11,  3.03s/it]
 47%|████▋     | 302/642 [17:43<17:43,  3.13s/it]
 47%|████▋     | 303/642 [17:46<16:41,  2.95s/it]
 47%|████▋     | 304/642 [17:49<17:08,  3.04s/it]
 48%|████▊     | 305/642 [17:52<17:07,  3.05s/it]
                                                 

 48%|████▊     | 305/642 [17:52<17:07,  3.05s/it]
 48%|████▊     | 306/642 [17:55<16:59,  3.03s/it]
 48%|████▊     | 307/642 [17:58<16:30,  2.96s/it]
 48%|████▊     | 308/642 [18:01<16:42,  3.00s/it]
 48%|████▊     | 309/642 [18:04<16:45,  3.02s/it]
 48%|████▊     | 310/642 [18:07<17:36,  3.18s/it]
                                                 

 48%|████▊     | 310/642 [18:08<17:36,  3.18s/it]
 48%|████▊     | 311/642 [18:11<18:09,  3.29s/it]
 49%|████▊     | 312/642 [18:14<18:10,  3.31s/it]
 49%|████▉     | 313/642 [18:17<17:41,  3.23s/it]
 49%|████▉     | 314/642 [18:21<18:07,  3.32s/it]
 49%|████▉     | 315/642 [18:24<17:39,  3.24s/it]
                                                 

 49%|████▉     | 315/642 [18:24<17:39,  3.24s/it]
 49%|████▉     | 316/642 [18:27<16:49,  3.10s/it]
 49%|████▉     | 317/642 [18:30<16:30,  3.05s/it]
 50%|████▉     | 318/642 [18:32<16:09,  2.99s/it]
 50%|████▉     | 319/642 [18:36<16:15,  3.02s/it]
 50%|████▉     | 320/642 [18:39<16:23,  3.06s/it]
                                                 

 50%|████▉     | 320/642 [18:39<16:23,  3.06s/it]
 50%|█████     | 321/642 [18:42<17:14,  3.22s/it]
 50%|█████     | 322/642 [18:45<16:24,  3.08s/it]
 50%|█████     | 323/642 [18:48<16:53,  3.18s/it]Saving model checkpoint to ./sft_models/checkpoint-323
Configuration saved in ./sft_models/checkpoint-323/config.json
Configuration saved in ./sft_models/checkpoint-323/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-323/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-323/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-323/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 50%|█████     | 324/642 [19:28<1:14:55, 14.14s/it]
 51%|█████     | 325/642 [19:31<56:55, 10.77s/it]  
                                                 

 51%|█████     | 325/642 [19:31<56:55, 10.77s/it]
 51%|█████     | 326/642 [19:34<44:51,  8.52s/it]
 51%|█████     | 327/642 [19:38<36:46,  7.01s/it]
 51%|█████     | 328/642 [19:41<30:13,  5.77s/it]
 51%|█████     | 329/642 [19:44<25:33,  4.90s/it]
 51%|█████▏    | 330/642 [19:47<22:45,  4.38s/it]
                                                 

 51%|█████▏    | 330/642 [19:47<22:45,  4.38s/it]
 52%|█████▏    | 331/642 [19:50<20:47,  4.01s/it]
 52%|█████▏    | 332/642 [19:53<19:16,  3.73s/it]
 52%|█████▏    | 333/642 [19:56<18:23,  3.57s/it]
 52%|█████▏    | 334/642 [19:59<17:34,  3.42s/it]
 52%|█████▏    | 335/642 [20:02<16:24,  3.21s/it]
                                                 

 52%|█████▏    | 335/642 [20:02<16:24,  3.21s/it]
 52%|█████▏    | 336/642 [20:05<16:10,  3.17s/it]
 52%|█████▏    | 337/642 [20:08<15:40,  3.08s/it]
 53%|█████▎    | 338/642 [20:11<15:21,  3.03s/it]
 53%|█████▎    | 339/642 [20:14<15:17,  3.03s/it]
 53%|█████▎    | 340/642 [20:17<15:19,  3.05s/it]
                                                 

 53%|█████▎    | 340/642 [20:17<15:19,  3.05s/it]
 53%|█████▎    | 341/642 [20:20<15:23,  3.07s/it]
 53%|█████▎    | 342/642 [20:23<15:37,  3.13s/it]
 53%|█████▎    | 343/642 [20:26<15:40,  3.15s/it]
 54%|█████▎    | 344/642 [20:30<16:33,  3.33s/it]
 54%|█████▎    | 345/642 [20:34<16:23,  3.31s/it]
                                                 

 54%|█████▎    | 345/642 [20:34<16:23,  3.31s/it]
 54%|█████▍    | 346/642 [20:36<15:15,  3.09s/it]
 54%|█████▍    | 347/642 [20:39<15:22,  3.13s/it]
 54%|█████▍    | 348/642 [20:43<15:28,  3.16s/it]
 54%|█████▍    | 349/642 [20:45<14:35,  2.99s/it]
 55%|█████▍    | 350/642 [20:48<15:01,  3.09s/it]
                                                 

 55%|█████▍    | 350/642 [20:49<15:01,  3.09s/it]
 55%|█████▍    | 351/642 [20:51<14:27,  2.98s/it]
 55%|█████▍    | 352/642 [20:54<14:53,  3.08s/it]
 55%|█████▍    | 353/642 [20:58<14:50,  3.08s/it]
 55%|█████▌    | 354/642 [21:01<15:20,  3.20s/it]
 55%|█████▌    | 355/642 [21:04<15:27,  3.23s/it]
                                                 

 55%|█████▌    | 355/642 [21:05<15:27,  3.23s/it]
 55%|█████▌    | 356/642 [21:08<15:20,  3.22s/it]
 56%|█████▌    | 357/642 [21:10<14:20,  3.02s/it]
 56%|█████▌    | 358/642 [21:13<14:41,  3.10s/it]
 56%|█████▌    | 359/642 [21:17<15:11,  3.22s/it]
 56%|█████▌    | 360/642 [21:20<14:37,  3.11s/it]
                                                 

 56%|█████▌    | 360/642 [21:20<14:37,  3.11s/it]
 56%|█████▌    | 361/642 [21:23<14:10,  3.03s/it]
 56%|█████▋    | 362/642 [21:26<14:18,  3.07s/it]
 57%|█████▋    | 363/642 [21:29<14:36,  3.14s/it]
 57%|█████▋    | 364/642 [21:32<14:13,  3.07s/it]
 57%|█████▋    | 365/642 [21:36<14:54,  3.23s/it]
                                                 

 57%|█████▋    | 365/642 [21:36<14:54,  3.23s/it]
 57%|█████▋    | 366/642 [21:39<14:42,  3.20s/it]
 57%|█████▋    | 367/642 [21:42<14:44,  3.22s/it]
 57%|█████▋    | 368/642 [21:45<13:59,  3.06s/it]
 57%|█████▋    | 369/642 [21:47<13:31,  2.97s/it]
 58%|█████▊    | 370/642 [21:51<13:40,  3.02s/it]
                                                 

 58%|█████▊    | 370/642 [21:51<13:40,  3.02s/it]
 58%|█████▊    | 371/642 [21:54<14:17,  3.16s/it]
 58%|█████▊    | 372/642 [21:57<13:57,  3.10s/it]
 58%|█████▊    | 373/642 [22:00<14:19,  3.20s/it]
 58%|█████▊    | 374/642 [22:03<14:00,  3.14s/it]
 58%|█████▊    | 375/642 [22:07<14:11,  3.19s/it]
                                                 

 58%|█████▊    | 375/642 [22:07<14:11,  3.19s/it]
 59%|█████▊    | 376/642 [22:10<14:40,  3.31s/it]
 59%|█████▊    | 377/642 [22:13<14:21,  3.25s/it]
 59%|█████▉    | 378/642 [22:16<13:47,  3.13s/it]
 59%|█████▉    | 379/642 [22:19<13:38,  3.11s/it]
 59%|█████▉    | 380/642 [22:22<13:28,  3.09s/it]
                                                 

 59%|█████▉    | 380/642 [22:23<13:28,  3.09s/it]
 59%|█████▉    | 381/642 [22:26<13:29,  3.10s/it]
 60%|█████▉    | 382/642 [22:29<13:33,  3.13s/it]
 60%|█████▉    | 383/642 [22:32<13:41,  3.17s/it]
 60%|█████▉    | 384/642 [22:35<12:56,  3.01s/it]
 60%|█████▉    | 385/642 [22:38<13:25,  3.14s/it]
                                                 

 60%|█████▉    | 385/642 [22:38<13:25,  3.14s/it]
 60%|██████    | 386/642 [22:41<12:49,  3.00s/it]
 60%|██████    | 387/642 [22:44<12:44,  3.00s/it]
 60%|██████    | 388/642 [22:47<13:06,  3.10s/it]
 61%|██████    | 389/642 [22:50<13:18,  3.16s/it]
 61%|██████    | 390/642 [22:54<13:24,  3.19s/it]
                                                 

 61%|██████    | 390/642 [22:54<13:24,  3.19s/it]
 61%|██████    | 391/642 [22:57<13:29,  3.23s/it]
 61%|██████    | 392/642 [23:00<12:57,  3.11s/it]
 61%|██████    | 393/642 [23:02<12:11,  2.94s/it]
 61%|██████▏   | 394/642 [23:06<12:48,  3.10s/it]
 62%|██████▏   | 395/642 [23:09<12:38,  3.07s/it]
                                                 

 62%|██████▏   | 395/642 [23:09<12:38,  3.07s/it]
 62%|██████▏   | 396/642 [23:12<12:56,  3.16s/it]
 62%|██████▏   | 397/642 [23:15<12:27,  3.05s/it]
 62%|██████▏   | 398/642 [23:18<12:06,  2.98s/it]
 62%|██████▏   | 399/642 [23:21<12:26,  3.07s/it]
 62%|██████▏   | 400/642 [23:24<12:22,  3.07s/it]
                                                 

 62%|██████▏   | 400/642 [23:24<12:22,  3.07s/it]
 62%|██████▏   | 401/642 [23:27<11:58,  2.98s/it]
 63%|██████▎   | 402/642 [23:30<12:07,  3.03s/it]
 63%|██████▎   | 403/642 [23:33<11:53,  2.98s/it]
 63%|██████▎   | 404/642 [23:36<12:07,  3.05s/it]
 63%|██████▎   | 405/642 [23:39<12:01,  3.04s/it]
                                                 

 63%|██████▎   | 405/642 [23:39<12:01,  3.04s/it]
 63%|██████▎   | 406/642 [23:42<12:08,  3.09s/it]
 63%|██████▎   | 407/642 [23:46<12:43,  3.25s/it]
 64%|██████▎   | 408/642 [23:49<12:16,  3.15s/it]
 64%|██████▎   | 409/642 [23:52<12:42,  3.27s/it]
 64%|██████▍   | 410/642 [23:55<11:57,  3.09s/it]
                                                 

 64%|██████▍   | 410/642 [23:55<11:57,  3.09s/it]
 64%|██████▍   | 411/642 [23:58<12:02,  3.13s/it]
 64%|██████▍   | 412/642 [24:01<12:00,  3.13s/it]
 64%|██████▍   | 413/642 [24:05<11:56,  3.13s/it]
 64%|██████▍   | 414/642 [24:08<11:57,  3.15s/it]
 65%|██████▍   | 415/642 [24:11<12:04,  3.19s/it]
                                                 

 65%|██████▍   | 415/642 [24:11<12:04,  3.19s/it]
 65%|██████▍   | 416/642 [24:14<11:53,  3.16s/it]
 65%|██████▍   | 417/642 [24:17<11:48,  3.15s/it]
 65%|██████▌   | 418/642 [24:20<11:31,  3.09s/it]
 65%|██████▌   | 419/642 [24:23<11:23,  3.07s/it]
 65%|██████▌   | 420/642 [24:26<11:21,  3.07s/it]
                                                 

 65%|██████▌   | 420/642 [24:26<11:21,  3.07s/it]
 66%|██████▌   | 421/642 [24:29<11:16,  3.06s/it]
 66%|██████▌   | 422/642 [24:32<11:03,  3.02s/it]
 66%|██████▌   | 423/642 [24:35<10:50,  2.97s/it]
 66%|██████▌   | 424/642 [24:38<10:43,  2.95s/it]
 66%|██████▌   | 425/642 [24:41<10:31,  2.91s/it]
                                                 

 66%|██████▌   | 425/642 [24:41<10:31,  2.91s/it]
 66%|██████▋   | 426/642 [24:44<10:35,  2.94s/it]
 67%|██████▋   | 427/642 [24:47<11:09,  3.11s/it]
 67%|██████▋   | 428/642 [24:51<11:45,  3.30s/it]
 67%|██████▋   | 429/642 [24:54<11:05,  3.12s/it]
 67%|██████▋   | 430/642 [24:57<10:48,  3.06s/it]
                                                 

 67%|██████▋   | 430/642 [24:57<10:48,  3.06s/it]
 67%|██████▋   | 431/642 [25:00<10:48,  3.08s/it]Saving model checkpoint to ./sft_models/checkpoint-431
Configuration saved in ./sft_models/checkpoint-431/config.json
Configuration saved in ./sft_models/checkpoint-431/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./sft_models/checkpoint-431/model.safetensors.index.json.
tokenizer config file saved in ./sft_models/checkpoint-431/tokenizer_config.json
Special tokens file saved in ./sft_models/checkpoint-431/special_tokens_map.json
tokenizer config file saved in ./sft_models/tokenizer_config.json
Special tokens file saved in ./sft_models/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]

 67%|██████▋   | 432/642 [25:41<50:25, 14.41s/it]
 67%|██████▋   | 433/642 [25:44<38:10, 10.96s/it]
 68%|██████▊   | 434/642 [25:46<29:33,  8.53s/it]
 68%|██████▊   | 435/642 [25:50<23:48,  6.90s/it]
                                                 

 68%|██████▊   | 435/642 [25:50<23:48,  6.90s/it]
 68%|██████▊   | 436/642 [25:52<19:28,  5.67s/it]
 68%|██████▊   | 437/642 [25:55<16:32,  4.84s/it]
 68%|██████▊   | 438/642 [25:58<14:45,  4.34s/it]
 68%|██████▊   | 439/642 [26:01<13:13,  3.91s/it]
 69%|██████▊   | 440/642 [26:05<12:35,  3.74s/it]
                                                 
{'loss': 2.4879, 'grad_norm': 304.0, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.05}
{'loss': 2.2869, 'grad_norm': 58.5, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.09}
{'loss': 1.8801, 'grad_norm': 208.0, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.14}
{'loss': 1.4544, 'grad_norm': 7.40625, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.19}
{'loss': 1.1734, 'grad_norm': 5.71875, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}
{'loss': 1.006, 'grad_norm': 4.65625, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.28}
{'loss': 0.9744, 'grad_norm': 3.984375, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.32}
{'loss': 0.9372, 'grad_norm': 4.34375, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.37}
{'loss': 0.8942, 'grad_norm': 3.6875, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.42}
{'loss': 0.8729, 'grad_norm': 3.6875, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}
{'loss': 0.8978, 'grad_norm': 3.8125, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.51}
{'loss': 0.8524, 'grad_norm': 3.546875, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.56}
{'loss': 0.8231, 'grad_norm': 3.5625, 'learning_rate': 2e-05, 'epoch': 0.6}
{'loss': 0.8315, 'grad_norm': 3.28125, 'learning_rate': 1.9996294632312766e-05, 'epoch': 0.65}
{'loss': 0.8262, 'grad_norm': 3.65625, 'learning_rate': 1.9985181275201e-05, 'epoch': 0.7}
{'loss': 0.8193, 'grad_norm': 3.109375, 'learning_rate': 1.9966668164479567e-05, 'epoch': 0.74}
{'loss': 0.8732, 'grad_norm': 3.28125, 'learning_rate': 1.9940769019724926e-05, 'epoch': 0.79}
{'loss': 0.8356, 'grad_norm': 3.03125, 'learning_rate': 1.9907503034107893e-05, 'epoch': 0.84}
{'loss': 0.8692, 'grad_norm': 3.0625, 'learning_rate': 1.9866894860170104e-05, 'epoch': 0.88}
{'loss': 0.8007, 'grad_norm': 2.984375, 'learning_rate': 1.9818974591554668e-05, 'epoch': 0.93}
{'loss': 0.8366, 'grad_norm': 3.296875, 'learning_rate': 1.9763777740704572e-05, 'epoch': 0.97}
{'loss': 0.8049, 'grad_norm': 2.625, 'learning_rate': 1.970134521254532e-05, 'epoch': 1.02}
{'loss': 0.6126, 'grad_norm': 2.921875, 'learning_rate': 1.9631723274171412e-05, 'epoch': 1.07}
{'loss': 0.6394, 'grad_norm': 2.96875, 'learning_rate': 1.9554963520559003e-05, 'epoch': 1.11}
{'loss': 0.6416, 'grad_norm': 3.421875, 'learning_rate': 1.9471122836330236e-05, 'epoch': 1.16}
{'loss': 0.6129, 'grad_norm': 3.40625, 'learning_rate': 1.9380263353597553e-05, 'epoch': 1.21}
{'loss': 0.6533, 'grad_norm': 3.359375, 'learning_rate': 1.9282452405919235e-05, 'epoch': 1.25}
{'loss': 0.6333, 'grad_norm': 3.515625, 'learning_rate': 1.9177762478400276e-05, 'epoch': 1.3}
{'loss': 0.6426, 'grad_norm': 2.921875, 'learning_rate': 1.9066271153975602e-05, 'epoch': 1.35}
{'loss': 0.6492, 'grad_norm': 3.421875, 'learning_rate': 1.8948061055915395e-05, 'epoch': 1.39}
{'loss': 0.6052, 'grad_norm': 3.09375, 'learning_rate': 1.882321978659519e-05, 'epoch': 1.44}
{'loss': 0.6471, 'grad_norm': 3.15625, 'learning_rate': 1.869183986257606e-05, 'epoch': 1.48}
{'loss': 0.6229, 'grad_norm': 3.15625, 'learning_rate': 1.8554018646043045e-05, 'epoch': 1.53}
{'loss': 0.6153, 'grad_norm': 3.46875, 'learning_rate': 1.840985827265262e-05, 'epoch': 1.58}
{'loss': 0.6302, 'grad_norm': 3.1875, 'learning_rate': 1.825946557584265e-05, 'epoch': 1.62}
{'loss': 0.6296, 'grad_norm': 3.421875, 'learning_rate': 1.810295200766097e-05, 'epoch': 1.67}
{'loss': 0.6141, 'grad_norm': 3.328125, 'learning_rate': 1.794043355617121e-05, 'epoch': 1.72}
{'loss': 0.6288, 'grad_norm': 3.3125, 'learning_rate': 1.7772030659497112e-05, 'epoch': 1.76}
{'loss': 0.6376, 'grad_norm': 2.984375, 'learning_rate': 1.7597868116569036e-05, 'epoch': 1.81}
{'loss': 0.6139, 'grad_norm': 3.25, 'learning_rate': 1.7418074994638752e-05, 'epoch': 1.86}
{'loss': 0.6259, 'grad_norm': 3.609375, 'learning_rate': 1.7232784533631148e-05, 'epoch': 1.9}
{'loss': 0.6429, 'grad_norm': 2.9375, 'learning_rate': 1.7042134047403613e-05, 'epoch': 1.95}
{'loss': 0.6532, 'grad_norm': 3.703125, 'learning_rate': 1.684626482198639e-05, 'epoch': 2.0}
{'loss': 0.4533, 'grad_norm': 3.71875, 'learning_rate': 1.6645322010879242e-05, 'epoch': 2.04}
{'loss': 0.3677, 'grad_norm': 4.71875, 'learning_rate': 1.6439454527482014e-05, 'epoch': 2.09}
{'loss': 0.3657, 'grad_norm': 3.703125, 'learning_rate': 1.6228814934738873e-05, 'epoch': 2.13}
{'loss': 0.3359, 'grad_norm': 4.3125, 'learning_rate': 1.6013559332077945e-05, 'epoch': 2.18}
{'loss': 0.3438, 'grad_norm': 5.3125, 'learning_rate': 1.5793847239730148e-05, 'epoch': 2.23}
{'loss': 0.3437, 'grad_norm': 4.4375, 'learning_rate': 1.5569841480512972e-05, 'epoch': 2.27}
{'loss': 0.3474, 'grad_norm': 4.09375, 'learning_rate': 1.534170805916681e-05, 'epoch': 2.32}
{'loss': 0.3529, 'grad_norm': 4.65625, 'learning_rate': 1.510961603933324e-05, 'epoch': 2.37}
{'loss': 0.3486, 'grad_norm': 3.96875, 'learning_rate': 1.4873737418266398e-05, 'epoch': 2.41}
{'loss': 0.3345, 'grad_norm': 4.15625, 'learning_rate': 1.4634246999370415e-05, 'epoch': 2.46}
{'loss': 0.3498, 'grad_norm': 4.125, 'learning_rate': 1.4391322262657206e-05, 'epoch': 2.51}
{'loss': 0.331, 'grad_norm': 3.71875, 'learning_rate': 1.4145143233220741e-05, 'epoch': 2.55}
{'loss': 0.3499, 'grad_norm': 4.28125, 'learning_rate': 1.3895892347825205e-05, 'epoch': 2.6}
{'loss': 0.348, 'grad_norm': 4.78125, 'learning_rate': 1.3643754319705956e-05, 'epoch': 2.65}
{'loss': 0.3527, 'grad_norm': 4.03125, 'learning_rate': 1.3388916001683412e-05, 'epoch': 2.69}
{'loss': 0.3207, 'grad_norm': 4.0625, 'learning_rate': 1.3131566247691387e-05, 'epoch': 2.74}
{'loss': 0.3458, 'grad_norm': 4.25, 'learning_rate': 1.2871895772822442e-05, 'epoch': 2.78}
{'loss': 0.3501, 'grad_norm': 4.0625, 'learning_rate': 1.261009701199395e-05, 'epoch': 2.83}
{'loss': 0.3583, 'grad_norm': 3.578125, 'learning_rate': 1.2346363977339698e-05, 'epoch': 2.88}
{'loss': 0.3328, 'grad_norm': 4.03125, 'learning_rate': 1.208089211443262e-05, 'epoch': 2.92}
{'loss': 0.3365, 'grad_norm': 3.890625, 'learning_rate': 1.1813878157445253e-05, 'epoch': 2.97}
{'loss': 0.3156, 'grad_norm': 3.53125, 'learning_rate': 1.1545519983355255e-05, 'epoch': 3.02}
{'loss': 0.1769, 'grad_norm': 3.90625, 'learning_rate': 1.1276016465303989e-05, 'epoch': 3.06}
{'loss': 0.1737, 'grad_norm': 5.78125, 'learning_rate': 1.1005567325216946e-05, 'epoch': 3.11}
{'loss': 0.165, 'grad_norm': 4.28125, 'learning_rate': 1.0734372985795062e-05, 'epoch': 3.16}
{'loss': 0.1701, 'grad_norm': 3.546875, 'learning_rate': 1.0462634421986786e-05, 'epoch': 3.2}
{'loss': 0.1707, 'grad_norm': 4.46875, 'learning_rate': 1.0190553012050868e-05, 'epoch': 3.25}
{'loss': 0.1603, 'grad_norm': 4.25, 'learning_rate': 9.918330388320235e-06, 'epoch': 3.29}
{'loss': 0.1662, 'grad_norm': 4.0625, 'learning_rate': 9.646168287777633e-06, 'epoch': 3.34}
{'loss': 0.159, 'grad_norm': 4.46875, 'learning_rate': 9.374268402553665e-06, 'epoch': 3.39}
{'loss': 0.163, 'grad_norm': 3.984375, 'learning_rate': 9.102832230458115e-06, 'epoch': 3.43}
{'loss': 0.1591, 'grad_norm': 4.09375, 'learning_rate': 8.83206092565522e-06, 'epoch': 3.48}
{'loss': 0.1706, 'grad_norm': 4.34375, 'learning_rate': 8.562155149593673e-06, 'epoch': 3.53}
{'loss': 0.1595, 'grad_norm': 4.4375, 'learning_rate': 8.293314922301715e-06, 'epoch': 3.57}
{'loss': 0.1637, 'grad_norm': 4.03125, 'learning_rate': 8.025739474157595e-06, 'epoch': 3.62}
{'loss': 0.1665, 'grad_norm': 3.828125, 'learning_rate': 7.759627098245207e-06, 'epoch': 3.67}
{'loss': 0.167, 'grad_norm': 3.953125, 'learning_rate': 7.49517500340432e-06, 'epoch': 3.71}
{'loss': 0.1533, 'grad_norm': 3.78125, 'learning_rate': 7.232579168084344e-06, 'epoch': 3.76}
{'loss': 0.1651, 'grad_norm': 4.3125, 'learning_rate': 6.972034195109885e-06, 'epoch': 3.81}
{'loss': 0.1673, 'grad_norm': 3.640625, 'learning_rate': 6.713733167465723e-06, 'epoch': 3.85}
{'loss': 0.1576, 'grad_norm': 4.125, 'learning_rate': 6.4578675052081395e-06, 'epoch': 3.9}
{'loss': 0.1688, 'grad_norm': 3.96875, 'learning_rate': 6.204626823608584e-06, 'epoch': 3.94}
{'loss': 0.1571, 'grad_norm': 3.78125, 'learning_rate': 5.954198792634782e-06, 'epoch': 3.99}
{'loss': 0.1248, 'grad_norm': 2.546875, 'learning_rate': 5.706768997873533e-06, 'epoch': 4.04}

 69%|██████▊   | 440/642 [26:05<12:35,  3.74s/it]
 69%|██████▊   | 441/642 [26:08<12:09,  3.63s/it]
 69%|██████▉   | 442/642 [26:11<11:44,  3.52s/it]
 69%|██████▉   | 443/642 [26:14<11:09,  3.36s/it]
 69%|██████▉   | 444/642 [26:18<10:55,  3.31s/it]
 69%|██████▉   | 445/642 [26:21<10:34,  3.22s/it]
                                                 

 69%|██████▉   | 445/642 [26:21<10:34,  3.22s/it]
 69%|██████▉   | 446/642 [26:23<10:04,  3.09s/it]
 70%|██████▉   | 447/642 [26:26<10:05,  3.10s/it]
 70%|██████▉   | 448/642 [26:30<10:07,  3.13s/it]
 70%|██████▉   | 449/642 [26:32<09:24,  2.93s/it]
 70%|███████   | 450/642 [26:35<09:10,  2.86s/it]
                                                 

 70%|███████   | 450/642 [26:35<09:10,  2.86s/it]
 70%|███████   | 451/642 [26:37<08:49,  2.77s/it]
 70%|███████   | 452/642 [26:41<09:13,  2.91s/it]
 71%|███████   | 453/642 [26:44<09:37,  3.05s/it]
 71%|███████   | 454/642 [26:47<09:56,  3.17s/it]
 71%|███████   | 455/642 [26:50<09:29,  3.04s/it]
                                                 

 71%|███████   | 455/642 [26:50<09:29,  3.04s/it]
 71%|███████   | 456/642 [26:54<09:46,  3.15s/it]
 71%|███████   | 457/642 [26:57<09:39,  3.13s/it]
 71%|███████▏  | 458/642 [27:00<09:33,  3.12s/it]
 71%|███████▏  | 459/642 [27:03<09:49,  3.22s/it]
 72%|███████▏  | 460/642 [27:06<09:38,  3.18s/it]
                                                 

 72%|███████▏  | 460/642 [27:06<09:38,  3.18s/it]
 72%|███████▏  | 461/642 [27:09<09:33,  3.17s/it]
 72%|███████▏  | 462/642 [27:12<09:21,  3.12s/it]
 72%|███████▏  | 463/642 [27:16<09:15,  3.10s/it]
 72%|███████▏  | 464/642 [27:18<09:01,  3.04s/it]
 72%|███████▏  | 465/642 [27:22<09:04,  3.08s/it]
                                                 

 72%|███████▏  | 465/642 [27:22<09:04,  3.08s/it]
 73%|███████▎  | 466/642 [27:25<08:57,  3.05s/it]
 73%|███████▎  | 467/642 [27:28<08:50,  3.03s/it]
 73%|███████▎  | 468/642 [27:31<08:58,  3.09s/it]
 73%|███████▎  | 469/642 [27:34<08:51,  3.07s/it]
 73%|███████▎  | 470/642 [27:37<08:38,  3.02s/it]
                                                 

 73%|███████▎  | 470/642 [27:37<08:38,  3.02s/it]
 73%|███████▎  | 471/642 [27:39<08:17,  2.91s/it]
 74%|███████▎  | 472/642 [27:42<08:18,  2.93s/it]
 74%|███████▎  | 473/642 [27:45<08:13,  2.92s/it]
 74%|███████▍  | 474/642 [27:49<08:46,  3.13s/it]
 74%|███████▍  | 475/642 [27:52<08:35,  3.09s/it]
                                                 

 74%|███████▍  | 475/642 [27:52<08:35,  3.09s/it]
 74%|███████▍  | 476/642 [27:55<08:26,  3.05s/it]
 74%|███████▍  | 477/642 [27:58<08:23,  3.05s/it]
 74%|███████▍  | 478/642 [28:01<08:06,  2.96s/it]
 75%|███████▍  | 479/642 [28:04<08:26,  3.11s/it]
 75%|███████▍  | 480/642 [28:08<08:46,  3.25s/it]
                                                 

 75%|███████▍  | 480/642 [28:08<08:46,  3.25s/it]
 75%|███████▍  | 481/642 [28:11<08:42,  3.25s/it]
 75%|███████▌  | 482/642 [28:14<08:29,  3.19s/it]
 75%|███████▌  | 483/642 [28:17<08:16,  3.12s/it]
 75%|███████▌  | 484/642 [28:20<07:54,  3.00s/it]
 76%|███████▌  | 485/642 [28:23<07:54,  3.02s/it]
                                                 

 76%|███████▌  | 485/642 [28:23<07:54,  3.02s/it]
 76%|███████▌  | 486/642 [28:26<07:59,  3.08s/it]
 76%|███████▌  | 487/642 [28:29<07:37,  2.95s/it]
 76%|███████▌  | 488/642 [28:32<07:41,  3.00s/it]
 76%|███████▌  | 489/642 [28:35<07:55,  3.11s/it]
 76%|███████▋  | 490/642 [28:38<07:34,  2.99s/it]
                                                 

 76%|███████▋  | 490/642 [28:38<07:34,  2.99s/it]
 76%|███████▋  | 491/642 [28:40<07:19,  2.91s/it]
 77%|███████▋  | 492/642 [28:43<07:19,  2.93s/it]
 77%|███████▋  | 493/642 [28:46<07:16,  2.93s/it]
 77%|███████▋  | 494/642 [28:49<07:18,  2.97s/it]
 77%|███████▋  | 495/642 [28:53<07:43,  3.15s/it]
                                                 

 77%|███████▋  | 495/642 [28:53<07:43,  3.15s/it]
 77%|███████▋  | 496/642 [28:56<07:35,  3.12s/it]
 77%|███████▋  | 497/642 [29:00<07:49,  3.24s/it]
 78%|███████▊  | 498/642 [29:03<07:56,  3.31s/it]
 78%|███████▊  | 499/642 [29:06<07:37,  3.20s/it]
 78%|███████▊  | 500/642 [29:10<07:55,  3.35s/it]
                                                 

 78%|███████▊  | 500/642 [29:10<07:55,  3.35s/it]
 78%|███████▊  | 501/642 [29:13<07:42,  3.28s/it]
 78%|███████▊  | 502/642 [29:16<07:25,  3.18s/it]
 78%|███████▊  | 503/642 [29:19<07:23,  3.19s/it]
 79%|███████▊  | 504/642 [29:22<07:23,  3.21s/it]
 79%|███████▊  | 505/642 [29:25<07:08,  3.13s/it]
                                                 

 79%|███████▊  | 505/642 [29:25<07:08,  3.13s/it]
 79%|███████▉  | 506/642 [29:28<06:45,  2.98s/it]
 79%|███████▉  | 507/642 [29:31<06:55,  3.07s/it]
 79%|███████▉  | 508/642 [29:34<07:02,  3.15s/it]
 79%|███████▉  | 509/642 [29:37<06:54,  3.12s/it]
 79%|███████▉  | 510/642 [29:41<07:10,  3.26s/it]
                                                 

 79%|███████▉  | 510/642 [29:41<07:10,  3.26s/it]
 80%|███████▉  | 511/642 [29:44<06:53,  3.16s/it]
 80%|███████▉  | 512/642 [29:47<06:46,  3.13s/it]
 80%|███████▉  | 513/642 [29:50<06:52,  3.19s/it]
 80%|████████  | 514/642 [29:54<06:53,  3.23s/it]
 80%|████████  | 515/642 [29:57<06:43,  3.17s/it]
                                                 

 80%|████████  | 515/642 [29:57<06:43,  3.17s/it]
 80%|████████  | 516/642 [30:00<06:42,  3.19s/it]
 81%|████████  | 517/642 [30:03<06:25,  3.08s/it]
 81%|████████  | 518/642 [30:06<06:29,  3.14s/it]
 81%|████████  | 519/642 [30:09<06:21,  3.10s/it]
 81%|████████  | 520/642 [30:12<06:18,  3.10s/it]
                                                 

 81%|████████  | 520/642 [30:12<06:18,  3.10s/it]
 81%|████████  | 521/642 [30:15<06:05,  3.02s/it]
 81%|████████▏ | 522/642 [30:18<06:13,  3.11s/it]
 81%|████████▏ | 523/642 [30:21<06:02,  3.04s/it]
 82%|████████▏ | 524/642 [30:25<06:10,  3.14s/it]
 82%|████████▏ | 525/642 [30:28<06:00,  3.08s/it]
                                                 

 82%|████████▏ | 525/642 [30:28<06:00,  3.08s/it]
 82%|████████▏ | 526/642 [30:31<06:13,  3.22s/it]
 82%|████████▏ | 527/642 [30:34<06:03,  3.16s/it]
 82%|████████▏ | 528/642 [30:37<05:51,  3.08s/it]
 82%|████████▏ | 529/642 [30:40<05:53,  3.13s/it]
 83%|████████▎ | 530/642 [30:43<05:53,  3.16s/it]
                                                 

 83%|████████▎ | 530/642 [30:44<05:53,  3.16s/it]
 83%|████████▎ | 531/642 [30:47<06:01,  3.26s/it]
 83%|████████▎ | 532/642 [30:50<05:52,  3.21s/it]
 83%|████████▎ | 533/642 [30:53<05:46,  3.18s/it]
 83%|████████▎ | 534/642 [30:56<05:46,  3.21s/it]
 83%|████████▎ | 535/642 [31:00<05:54,  3.31s/it]
                                                 

 83%|████████▎ | 535/642 [31:00<05:54,  3.31s/it]
 83%|████████▎ | 536/642 [31:03<05:34,  3.16s/it]
 84%|████████▎ | 537/642 [31:06<05:22,  3.07s/it]
 84%|████████▍ | 538/642 [31:08<05:09,  2.97s/it]Saving model checkpoint to ./sft_models/checkpoint-538
Configuration saved in ./sft_models/checkpoint-538/config.json
Configuration saved in ./sft_models/checkpoint-538/generation_config.json
{'loss': 0.0991, 'grad_norm': 2.1875, 'learning_rate': 5.462520802998108e-06, 'epoch': 4.08}
{'loss': 0.0951, 'grad_norm': 3.234375, 'learning_rate': 5.221635213882295e-06, 'epoch': 4.13}
{'loss': 0.1023, 'grad_norm': 3.46875, 'learning_rate': 4.9842907444617415e-06, 'epoch': 4.18}
{'loss': 0.0941, 'grad_norm': 2.90625, 'learning_rate': 4.750663284442001e-06, 'epoch': 4.22}
{'loss': 0.0942, 'grad_norm': 2.984375, 'learning_rate': 4.52092596895131e-06, 'epoch': 4.27}
{'loss': 0.0941, 'grad_norm': 2.90625, 'learning_rate': 4.295249050234738e-06, 'epoch': 4.32}
{'loss': 0.0956, 'grad_norm': 3.046875, 'learning_rate': 4.07379977


Traceback (most recent call last):
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 139, in <module>
    train_dataset = load_dataset('json', data_files=script_args.train_set_path)['train'].shuffle(seed=42)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 1562, in dataset_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/load.py", line 942, in get_module
    data_files = DataFilesDict.from_patterns(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/data_files.py", line 721, in from_patterns
    else DataFilesList.from_patterns(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/data_files.py", line 624, in from_patterns
    resolve_pattern(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/datasets/data_files.py", line 411, in resolve_pattern
    raise FileNotFoundError(error_msg)
FileNotFoundError: Unable to find '/home/cyc2202/LLM-as-Latent-Variable-Model/outputs/gemma-2-2b-it-restem/round-1/sample_output.jsonl'



Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 3448 examples [00:00, 68940.67 examples/s]
Map (num_proc=16):   0%|          | 0/3448 [00:00<?, ? examples/s]Map (num_proc=16): 100%|██████████| 3448/3448 [00:00<00:00, 22631.89 examples/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': model_init_kwargs, max_seq_length. Will not be supported from version '0.13.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:175: UserWarning: You passed `model_init_kwargs` to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:202: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
--- Logging error ---
Traceback (most recent call last):
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 1110, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 953, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 687, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/logging/__init__.py", line 377, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/home/cyc2202/LLM-as-Latent-Variable-Model/sft.py", line 153, in <module>
    trainer = SFTTrainer(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py", line 101, in inner_f
    return f(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 165, in wrapped_func
    return func(*args, **kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py", line 209, in __init__
    model = AutoModelForCausalLM.from_pretrained(model, **model_init_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4097, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 963, in __init__
    super().__init__(config)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/modeling_utils.py", line 1432, in __init__
    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1235, in from_model_config
    generation_config = cls.from_dict(config_dict, return_unused_kwargs=False, _from_model_config=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 1093, in from_dict
    config = cls(**{**config_dict, **kwargs})
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 475, in __init__
    self.validate(is_init=True)
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/generation/configuration_utils.py", line 751, in validate
    logger.warning_once(
  File "/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/transformers/utils/logging.py", line 328, in warning_once
    self.warning(*args, **kwargs)
Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'
Arguments: (<class 'UserWarning'>,)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.60it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  6.08it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.80it/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
Map:   0%|          | 0/3448 [00:00<?, ? examples/s]Map:  29%|██▉       | 1000/3448 [00:00<00:00, 3170.59 examples/s]Map:  58%|█████▊    | 2000/3448 [00:00<00:00, 3145.53 examples/s]Map:  87%|████████▋ | 3000/3448 [00:00<00:00, 3167.08 examples/s]Map: 100%|██████████| 3448/3448 [00:01<00:00, 3158.98 examples/s]Map: 100%|██████████| 3448/3448 [00:01<00:00, 3149.09 examples/s]
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.
  warnings.warn(
[2024-11-13 05:56:03,864] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using auto half precision backend
***** Running training *****
  Num examples = 3,448
  Num Epochs = 6
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 4
  Total optimization steps = 642
  Number of trainable parameters = 2,614,341,888
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yutongyin2028 (yutongyin). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /home/cyc2202/LLM-as-Latent-Variable-Model/wandb/run-20241113_055605-7oikn82h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma2-2b-restem
wandb: ⭐️ View project at https://wandb.ai/yutongyin/huggingface
wandb: 🚀 View run at https://wandb.ai/yutongyin/huggingface/runs/7oikn82h
  0%|          | 0/642 [00:00<?, ?it/s]/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
  0%|          | 1/642 [00:03<34:02,  3.19s/it]  0%|          | 2/642 [00:06<32:19,  3.03s/it]  0%|          | 3/642 [00:09<32:39,  3.07s/it]  1%|          | 4/642 [00:12<31:54,  3.00s/it]  1%|          | 5/642 [00:15<31:36,  2.98s/it]                                                 1%|          | 5/642 [00:15<31:36,  2.98s/it]  1%|          | 6/642 [00:18<32:19,  3.05s/it]  1%|          | 7/642 [00:21<34:37,  3.27s/it]  1%|          | 8/642 [00:24<32:52,  3.11s/it]  1%|▏         | 9/642 [00:27<32:12,  3.05s/it]  2%|▏         | 10/642 [00:30<32:38,  3.10s/it]                                                  2%|▏         | 10/642 [00:31<32:38,  3.10s/it]  2%|▏         | 11/642 [00:33<32:27,  3.09s/it]  2%|▏         | 12/642 [00:37<32:27,  3.09s/it]  2%|▏         | 13/642 [00:39<30:52,  2.95s/it]  2%|▏         | 14/642 [00:42<31:48,  3.04s/it]  2%|▏         | 15/642 [00:45<31:43,  3.04s/it]                                                  2%|▏         | 15/642 [00:46<31:43,  3.04s/it]  2%|▏         | 16/642 [00:48<30:35,  2.93s/it]  3%|▎         | 17/642 [00:51<30:23,  2.92s/it]  3%|▎         | 18/642 [00:54<30:28,  2.93s/it]  3%|▎         | 19/642 [00:56<29:00,  2.79s/it]  3%|▎         | 20/642 [01:00<30:04,  2.90s/it]                                                  3%|▎         | 20/642 [01:00<30:04,  2.90s/it]  3%|▎         | 21/642 [01:03<30:16,  2.92s/it]  3%|▎         | 22/642 [01:06<30:24,  2.94s/it]  4%|▎         | 23/642 [01:09<30:33,  2.96s/it]  4%|▎         | 24/642 [01:11<29:55,  2.91s/it]  4%|▍         | 25/642 [01:14<29:46,  2.90s/it]                                                  4%|▍         | 25/642 [01:14<29:46,  2.90s/it]  4%|▍         | 26/642 [01:16<27:42,  2.70s/it]  4%|▍         | 27/642 [01:19<27:46,  2.71s/it]  4%|▍         | 28/642 [01:22<28:34,  2.79s/it]  5%|▍         | 29/642 [01:26<32:35,  3.19s/it]  5%|▍         | 30/642 [01:29<31:57,  3.13s/it]                                                  5%|▍         | 30/642 [01:29<31:57,  3.13s/it]  5%|▍         | 31/642 [01:32<30:21,  2.98s/it]  5%|▍         | 32/642 [01:35<30:51,  3.04s/it]  5%|▌         | 33/642 [01:38<30:37,  3.02s/it]  5%|▌         | 34/642 [01:41<31:29,  3.11s/it]  5%|▌         | 35/642 [01:44<31:22,  3.10s/it]                                                  5%|▌         | 35/642 [01:45<31:22,  3.10s/it]  6%|▌         | 36/642 [01:47<30:16,  3.00s/it]  6%|▌         | 37/642 [01:50<30:11,  2.99s/it]  6%|▌         | 38/642 [01:53<30:11,  3.00s/it]  6%|▌         | 39/642 [01:56<29:08,  2.90s/it]  6%|▌         | 40/642 [01:59<28:52,  2.88s/it]                                                  6%|▌         | 40/642 [01:59<28:52,  2.88s/it]  6%|▋         | 41/642 [02:02<28:50,  2.88s/it]  7%|▋         | 42/642 [02:05<29:39,  2.97s/it]  7%|▋         | 43/642 [02:08<31:28,  3.15s/it]  7%|▋         | 44/642 [02:11<30:12,  3.03s/it]  7%|▋         | 45/642 [02:14<30:56,  3.11s/it]                                                  7%|▋         | 45/642 [02:15<30:56,  3.11s/it]  7%|▋         | 46/642 [02:18<31:40,  3.19s/it]  7%|▋         | 47/642 [02:21<31:41,  3.20s/it]  7%|▋         | 48/642 [02:24<32:07,  3.25s/it]  8%|▊         | 49/642 [02:28<32:19,  3.27s/it]  8%|▊         | 50/642 [02:31<32:17,  3.27s/it]                                                  8%|▊         | 50/642 [02:31<32:17,  3.27s/it]  8%|▊         | 51/642 [02:34<32:24,  3.29s/it]  8%|▊         | 52/642 [02:37<31:10,  3.17s/it]  8%|▊         | 53/642 [02:40<29:32,  3.01s/it]  8%|▊         | 54/642 [02:43<30:20,  3.10s/it]  9%|▊         | 55/642 [02:46<29:28,  3.01s/it]                                                  9%|▊         | 55/642 [02:46<29:28,  3.01s/it]  9%|▊         | 56/642 [02:49<29:20,  3.00s/it]  9%|▉         | 57/642 [02:52<29:33,  3.03s/it]  9%|▉         | 58/642 [02:56<31:02,  3.19s/it]  9%|▉         | 59/642 [02:59<30:42,  3.16s/it]  9%|▉         | 60/642 [03:02<30:20,  3.13s/it]                                                  9%|▉         | 60/642 [03:02<30:20,  3.13s/it] 10%|▉         | 61/642 [03:05<29:49,  3.08s/it] 10%|▉         | 62/642 [03:08<30:08,  3.12s/it] 10%|▉         | 63/642 [03:11<30:22,  3.15s/it] 10%|▉         | 64/642 [03:14<29:23,  3.05s/it] 10%|█         | 65/642 [03:17<29:22,  3.05s/it]                                                 10%|█         | 65/642 [03:17<29:22,  3.05s/it] 10%|█         | 66/642 [03:20<29:57,  3.12s/it] 10%|█         | 67/642 [03:24<30:37,  3.20s/it] 11%|█         | 68/642 [03:27<30:17,  3.17s/it] 11%|█         | 69/642 [03:30<30:54,  3.24s/it] 11%|█         | 70/642 [03:33<29:46,  3.12s/it]                                                 11%|█         | 70/642 [03:33<29:46,  3.12s/it] 11%|█         | 71/642 [03:36<28:55,  3.04s/it] 11%|█         | 72/642 [03:39<29:17,  3.08s/it] 11%|█▏        | 73/642 [03:42<29:25,  3.10s/it] 12%|█▏        | 74/642 [03:45<29:18,  3.10s/it] 12%|█▏        | 75/642 [03:49<30:08,  3.19s/it]                                                 12%|█▏        | 75/642 [03:49<30:08,  3.19s/it] 12%|█▏        | 76/642 [03:52<30:17,  3.21s/it] 12%|█▏        | 77/642 [03:55<29:11,  3.10s/it] 12%|█▏        | 78/642 [03:58<28:38,  3.05s/it] 12%|█▏        | 79/642 [04:01<28:22,  3.02s/it] 12%|█▏        | 80/642 [04:04<29:16,  3.13s/it]                                                 12%|█▏        | 80/642 [04:04<29:16,  3.13s/it] 13%|█▎        | 81/642 [04:07<28:39,  3.06s/it] 13%|█▎        | 82/642 [04:10<27:38,  2.96s/it] 13%|█▎        | 83/642 [04:13<29:24,  3.16s/it] 13%|█▎        | 84/642 [04:16<28:26,  3.06s/it] 13%|█▎        | 85/642 [04:19<28:59,  3.12s/it]                                                 13%|█▎        | 85/642 [04:20<28:59,  3.12s/it] 13%|█▎        | 86/642 [04:23<29:04,  3.14s/it] 14%|█▎        | 87/642 [04:26<29:38,  3.20s/it] 14%|█▎        | 88/642 [04:29<29:04,  3.15s/it] 14%|█▍        | 89/642 [04:32<28:19,  3.07s/it] 14%|█▍        | 90/642 [04:34<27:13,  2.96s/it]                                                 14%|█▍        | 90/642 [04:35<27:13,  2.96s/it] 14%|█▍        | 91/642 [04:38<28:52,  3.15s/it] 14%|█▍        | 92/642 [04:41<29:06,  3.18s/it] 14%|█▍        | 93/642 [04:44<28:14,  3.09s/it] 15%|█▍        | 94/642 [04:47<27:37,  3.03s/it] 15%|█▍        | 95/642 [04:51<29:01,  3.18s/it]                                                 15%|█▍        | 95/642 [04:51<29:01,  3.18s/it] 15%|█▍        | 96/642 [04:54<28:16,  3.11s/it] 15%|█▌        | 97/642 [04:57<30:18,  3.34s/it] 15%|█▌        | 98/642 [05:00<29:04,  3.21s/it] 15%|█▌        | 99/642 [05:04<29:26,  3.25s/it] 16%|█▌        | 100/642 [05:06<28:02,  3.10s/it]                                                  16%|█▌        | 100/642 [05:07<28:02,  3.10s/it] 16%|█▌        | 101/642 [05:10<28:29,  3.16s/it] 16%|█▌        | 102/642 [05:13<27:34,  3.06s/it] 16%|█▌        | 103/642 [05:16<28:07,  3.13s/it] 16%|█▌        | 104/642 [05:19<28:01,  3.13s/it] 16%|█▋        | 105/642 [05:22<27:57,  3.12s/it]                                                  16%|█▋        | 105/642 [05:22<27:57,  3.12s/it] 17%|█▋        | 106/642 [05:25<27:09,  3.04s/it] 17%|█▋        | 107/642 [05:28<26:55,  3.02s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-107
Configuration saved in ./outputs/restem_6epoch/checkpoint-107/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-107/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-107/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-107/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-107/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 17%|█▋        | 108/642 [05:56<1:33:19, 10.49s/it] 17%|█▋        | 109/642 [05:59<1:13:48,  8.31s/it] 17%|█▋        | 110/642 [06:02<1:00:03,  6.77s/it]                                                    17%|█▋        | 110/642 [06:02<1:00:03,  6.77s/it] 17%|█▋        | 111/642 [06:06<50:42,  5.73s/it]   17%|█▋        | 112/642 [06:09<43:29,  4.92s/it] 18%|█▊        | 113/642 [06:12<38:10,  4.33s/it] 18%|█▊        | 114/642 [06:14<34:17,  3.90s/it] 18%|█▊        | 115/642 [06:17<32:02,  3.65s/it]                                                  18%|█▊        | 115/642 [06:18<32:02,  3.65s/it] 18%|█▊        | 116/642 [06:20<29:50,  3.40s/it] 18%|█▊        | 117/642 [06:23<28:18,  3.24s/it] 18%|█▊        | 118/642 [06:27<29:11,  3.34s/it] 19%|█▊        | 119/642 [06:30<29:50,  3.42s/it] 19%|█▊        | 120/642 [06:34<29:19,  3.37s/it]                                                  19%|█▊        | 120/642 [06:34<29:19,  3.37s/it] 19%|█▉        | 121/642 [06:36<27:08,  3.13s/it] 19%|█▉        | 122/642 [06:39<26:41,  3.08s/it] 19%|█▉        | 123/642 [06:42<26:09,  3.02s/it] 19%|█▉        | 124/642 [06:45<25:39,  2.97s/it] 19%|█▉        | 125/642 [06:48<26:07,  3.03s/it]                                                  19%|█▉        | 125/642 [06:48<26:07,  3.03s/it] 20%|█▉        | 126/642 [06:51<25:29,  2.96s/it] 20%|█▉        | 127/642 [06:54<25:52,  3.02s/it] 20%|█▉        | 128/642 [06:57<25:39,  2.99s/it] 20%|██        | 129/642 [07:00<25:46,  3.01s/it] 20%|██        | 130/642 [07:03<25:49,  3.03s/it]                                                  20%|██        | 130/642 [07:03<25:49,  3.03s/it] 20%|██        | 131/642 [07:06<25:35,  3.01s/it] 21%|██        | 132/642 [07:09<25:10,  2.96s/it] 21%|██        | 133/642 [07:12<26:08,  3.08s/it] 21%|██        | 134/642 [07:15<25:47,  3.05s/it] 21%|██        | 135/642 [07:18<25:54,  3.07s/it]                                                  21%|██        | 135/642 [07:18<25:54,  3.07s/it] 21%|██        | 136/642 [07:21<24:50,  2.95s/it] 21%|██▏       | 137/642 [07:24<25:47,  3.06s/it] 21%|██▏       | 138/642 [07:27<25:01,  2.98s/it] 22%|██▏       | 139/642 [07:30<24:30,  2.92s/it] 22%|██▏       | 140/642 [07:33<24:52,  2.97s/it]                                                  22%|██▏       | 140/642 [07:33<24:52,  2.97s/it] 22%|██▏       | 141/642 [07:36<25:07,  3.01s/it] 22%|██▏       | 142/642 [07:39<25:45,  3.09s/it] 22%|██▏       | 143/642 [07:42<25:18,  3.04s/it] 22%|██▏       | 144/642 [07:45<25:19,  3.05s/it] 23%|██▎       | 145/642 [07:49<25:47,  3.11s/it]                                                  23%|██▎       | 145/642 [07:49<25:47,  3.11s/it] 23%|██▎       | 146/642 [07:51<25:05,  3.03s/it] 23%|██▎       | 147/642 [07:55<25:56,  3.15s/it] 23%|██▎       | 148/642 [07:58<25:23,  3.08s/it] 23%|██▎       | 149/642 [08:01<25:40,  3.12s/it] 23%|██▎       | 150/642 [08:04<26:13,  3.20s/it]                                                  23%|██▎       | 150/642 [08:05<26:13,  3.20s/it] 24%|██▎       | 151/642 [08:08<27:27,  3.36s/it] 24%|██▎       | 152/642 [08:11<26:35,  3.26s/it] 24%|██▍       | 153/642 [08:14<26:40,  3.27s/it] 24%|██▍       | 154/642 [08:17<25:37,  3.15s/it] 24%|██▍       | 155/642 [08:21<26:11,  3.23s/it]                                                  24%|██▍       | 155/642 [08:21<26:11,  3.23s/it] 24%|██▍       | 156/642 [08:24<25:55,  3.20s/it] 24%|██▍       | 157/642 [08:27<25:13,  3.12s/it] 25%|██▍       | 158/642 [08:30<24:35,  3.05s/it] 25%|██▍       | 159/642 [08:33<24:02,  2.99s/it] 25%|██▍       | 160/642 [08:36<24:47,  3.09s/it]                                                  25%|██▍       | 160/642 [08:36<24:47,  3.09s/it] 25%|██▌       | 161/642 [08:39<25:40,  3.20s/it] 25%|██▌       | 162/642 [08:42<24:50,  3.11s/it] 25%|██▌       | 163/642 [08:45<24:44,  3.10s/it] 26%|██▌       | 164/642 [08:48<24:53,  3.12s/it] 26%|██▌       | 165/642 [08:52<25:07,  3.16s/it]                                                  26%|██▌       | 165/642 [08:52<25:07,  3.16s/it] 26%|██▌       | 166/642 [08:55<24:32,  3.09s/it] 26%|██▌       | 167/642 [08:58<24:47,  3.13s/it] 26%|██▌       | 168/642 [09:01<25:34,  3.24s/it] 26%|██▋       | 169/642 [09:05<25:48,  3.27s/it] 26%|██▋       | 170/642 [09:08<26:16,  3.34s/it]                                                  26%|██▋       | 170/642 [09:08<26:16,  3.34s/it] 27%|██▋       | 171/642 [09:11<25:46,  3.28s/it] 27%|██▋       | 172/642 [09:14<25:01,  3.19s/it] 27%|██▋       | 173/642 [09:17<23:33,  3.01s/it] 27%|██▋       | 174/642 [09:20<23:16,  2.98s/it] 27%|██▋       | 175/642 [09:23<23:01,  2.96s/it]                                                  27%|██▋       | 175/642 [09:23<23:01,  2.96s/it] 27%|██▋       | 176/642 [09:26<23:49,  3.07s/it] 28%|██▊       | 177/642 [09:29<23:50,  3.08s/it] 28%|██▊       | 178/642 [09:32<24:04,  3.11s/it] 28%|██▊       | 179/642 [09:36<24:26,  3.17s/it] 28%|██▊       | 180/642 [09:39<23:56,  3.11s/it]                                                  28%|██▊       | 180/642 [09:39<23:56,  3.11s/it] 28%|██▊       | 181/642 [09:42<23:32,  3.06s/it] 28%|██▊       | 182/642 [09:45<23:53,  3.12s/it] 29%|██▊       | 183/642 [09:48<24:25,  3.19s/it] 29%|██▊       | 184/642 [09:51<23:40,  3.10s/it] 29%|██▉       | 185/642 [09:54<22:47,  2.99s/it]                                                  29%|██▉       | 185/642 [09:54<22:47,  2.99s/it] 29%|██▉       | 186/642 [09:57<22:25,  2.95s/it] 29%|██▉       | 187/642 [10:00<22:24,  2.96s/it] 29%|██▉       | 188/642 [10:03<22:38,  2.99s/it] 29%|██▉       | 189/642 [10:06<22:11,  2.94s/it] 30%|██▉       | 190/642 [10:08<22:01,  2.92s/it]                                                  30%|██▉       | 190/642 [10:09<22:01,  2.92s/it] 30%|██▉       | 191/642 [10:11<21:35,  2.87s/it] 30%|██▉       | 192/642 [10:14<21:59,  2.93s/it] 30%|███       | 193/642 [10:17<21:29,  2.87s/it] 30%|███       | 194/642 [10:20<22:16,  2.98s/it] 30%|███       | 195/642 [10:24<24:41,  3.32s/it]                                                  30%|███       | 195/642 [10:24<24:41,  3.32s/it] 31%|███       | 196/642 [10:28<25:09,  3.39s/it] 31%|███       | 197/642 [10:31<25:22,  3.42s/it] 31%|███       | 198/642 [10:35<24:39,  3.33s/it] 31%|███       | 199/642 [10:38<23:56,  3.24s/it] 31%|███       | 200/642 [10:41<24:07,  3.28s/it]                                                  31%|███       | 200/642 [10:41<24:07,  3.28s/it] 31%|███▏      | 201/642 [10:44<23:30,  3.20s/it] 31%|███▏      | 202/642 [10:47<22:32,  3.07s/it] 32%|███▏      | 203/642 [10:49<21:51,  2.99s/it] 32%|███▏      | 204/642 [10:53<22:54,  3.14s/it] 32%|███▏      | 205/642 [10:56<23:03,  3.16s/it]                                                  32%|███▏      | 205/642 [10:56<23:03,  3.16s/it] 32%|███▏      | 206/642 [10:59<22:51,  3.15s/it] 32%|███▏      | 207/642 [11:02<22:50,  3.15s/it] 32%|███▏      | 208/642 [11:05<22:15,  3.08s/it] 33%|███▎      | 209/642 [11:09<22:21,  3.10s/it] 33%|███▎      | 210/642 [11:11<21:57,  3.05s/it]                                                  33%|███▎      | 210/642 [11:12<21:57,  3.05s/it] 33%|███▎      | 211/642 [11:14<21:47,  3.03s/it] 33%|███▎      | 212/642 [11:18<22:30,  3.14s/it] 33%|███▎      | 213/642 [11:21<21:51,  3.06s/it] 33%|███▎      | 214/642 [11:24<22:09,  3.11s/it] 33%|███▎      | 215/642 [11:27<22:17,  3.13s/it]                                                  33%|███▎      | 215/642 [11:27<22:17,  3.13s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-215
Configuration saved in ./outputs/restem_6epoch/checkpoint-215/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-215/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-215/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-215/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-215/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 34%|███▎      | 216/642 [12:22<2:12:25, 18.65s/it] 34%|███▍      | 217/642 [12:25<1:38:52, 13.96s/it] 34%|███▍      | 218/642 [12:28<1:15:21, 10.66s/it] 34%|███▍      | 219/642 [12:31<58:46,  8.34s/it]   34%|███▍      | 220/642 [12:34<47:02,  6.69s/it]                                                  34%|███▍      | 220/642 [12:34<47:02,  6.69s/it] 34%|███▍      | 221/642 [12:37<39:02,  5.56s/it] 35%|███▍      | 222/642 [12:39<32:53,  4.70s/it] 35%|███▍      | 223/642 [12:42<28:46,  4.12s/it] 35%|███▍      | 224/642 [12:45<26:41,  3.83s/it] 35%|███▌      | 225/642 [12:48<24:45,  3.56s/it]                                                  35%|███▌      | 225/642 [12:48<24:45,  3.56s/it] 35%|███▌      | 226/642 [12:51<23:41,  3.42s/it] 35%|███▌      | 227/642 [12:54<22:24,  3.24s/it] 36%|███▌      | 228/642 [12:57<22:01,  3.19s/it] 36%|███▌      | 229/642 [13:00<21:42,  3.15s/it] 36%|███▌      | 230/642 [13:03<21:22,  3.11s/it]                                                  36%|███▌      | 230/642 [13:03<21:22,  3.11s/it] 36%|███▌      | 231/642 [13:06<21:22,  3.12s/it] 36%|███▌      | 232/642 [13:10<22:00,  3.22s/it] 36%|███▋      | 233/642 [13:14<22:53,  3.36s/it] 36%|███▋      | 234/642 [13:17<22:47,  3.35s/it] 37%|███▋      | 235/642 [13:20<23:07,  3.41s/it]                                                  37%|███▋      | 235/642 [13:21<23:07,  3.41s/it] 37%|███▋      | 236/642 [13:24<23:20,  3.45s/it] 37%|███▋      | 237/642 [13:27<22:58,  3.40s/it] 37%|███▋      | 238/642 [13:30<21:35,  3.21s/it] 37%|███▋      | 239/642 [13:33<21:04,  3.14s/it] 37%|███▋      | 240/642 [13:36<21:25,  3.20s/it]                                                  37%|███▋      | 240/642 [13:36<21:25,  3.20s/it] 38%|███▊      | 241/642 [13:39<20:55,  3.13s/it] 38%|███▊      | 242/642 [13:43<21:05,  3.16s/it] 38%|███▊      | 243/642 [13:45<20:36,  3.10s/it] 38%|███▊      | 244/642 [13:48<19:54,  3.00s/it] 38%|███▊      | 245/642 [13:51<19:39,  2.97s/it]                                                  38%|███▊      | 245/642 [13:51<19:39,  2.97s/it] 38%|███▊      | 246/642 [13:54<19:22,  2.94s/it] 38%|███▊      | 247/642 [13:57<19:32,  2.97s/it] 39%|███▊      | 248/642 [14:00<19:15,  2.93s/it] 39%|███▉      | 249/642 [14:03<19:38,  3.00s/it] 39%|███▉      | 250/642 [14:06<20:08,  3.08s/it]                                                  39%|███▉      | 250/642 [14:06<20:08,  3.08s/it] 39%|███▉      | 251/642 [14:09<19:58,  3.06s/it] 39%|███▉      | 252/642 [14:12<19:17,  2.97s/it] 39%|███▉      | 253/642 [14:15<19:47,  3.05s/it] 40%|███▉      | 254/642 [14:18<19:39,  3.04s/it] 40%|███▉      | 255/642 [14:21<18:41,  2.90s/it]                                                  40%|███▉      | 255/642 [14:21<18:41,  2.90s/it] 40%|███▉      | 256/642 [14:24<18:31,  2.88s/it] 40%|████      | 257/642 [14:27<18:40,  2.91s/it] 40%|████      | 258/642 [14:30<19:13,  3.00s/it] 40%|████      | 259/642 [14:33<19:06,  2.99s/it] 40%|████      | 260/642 [14:36<19:21,  3.04s/it]                                                  40%|████      | 260/642 [14:36<19:21,  3.04s/it] 41%|████      | 261/642 [14:39<19:42,  3.10s/it] 41%|████      | 262/642 [14:42<19:29,  3.08s/it] 41%|████      | 263/642 [14:45<19:34,  3.10s/it] 41%|████      | 264/642 [14:49<19:48,  3.14s/it] 41%|████▏     | 265/642 [14:52<20:22,  3.24s/it]                                                  41%|████▏     | 265/642 [14:52<20:22,  3.24s/it] 41%|████▏     | 266/642 [14:55<19:51,  3.17s/it] 42%|████▏     | 267/642 [14:58<19:28,  3.12s/it] 42%|████▏     | 268/642 [15:01<19:43,  3.17s/it] 42%|████▏     | 269/642 [15:04<19:04,  3.07s/it] 42%|████▏     | 270/642 [15:07<18:51,  3.04s/it]                                                  42%|████▏     | 270/642 [15:07<18:51,  3.04s/it] 42%|████▏     | 271/642 [15:10<18:47,  3.04s/it] 42%|████▏     | 272/642 [15:14<19:28,  3.16s/it] 43%|████▎     | 273/642 [15:17<18:53,  3.07s/it] 43%|████▎     | 274/642 [15:20<19:30,  3.18s/it] 43%|████▎     | 275/642 [15:23<18:45,  3.07s/it]                                                  43%|████▎     | 275/642 [15:23<18:45,  3.07s/it] 43%|████▎     | 276/642 [15:26<18:13,  2.99s/it] 43%|████▎     | 277/642 [15:29<17:54,  2.94s/it] 43%|████▎     | 278/642 [15:32<18:13,  3.01s/it] 43%|████▎     | 279/642 [15:35<18:55,  3.13s/it] 44%|████▎     | 280/642 [15:38<18:50,  3.12s/it]                                                  44%|████▎     | 280/642 [15:38<18:50,  3.12s/it] 44%|████▍     | 281/642 [15:42<19:17,  3.21s/it] 44%|████▍     | 282/642 [15:45<19:03,  3.18s/it] 44%|████▍     | 283/642 [15:48<18:32,  3.10s/it] 44%|████▍     | 284/642 [15:50<17:49,  2.99s/it] 44%|████▍     | 285/642 [15:54<18:15,  3.07s/it]                                                  44%|████▍     | 285/642 [15:54<18:15,  3.07s/it] 45%|████▍     | 286/642 [15:57<17:55,  3.02s/it] 45%|████▍     | 287/642 [16:00<18:01,  3.05s/it] 45%|████▍     | 288/642 [16:03<18:01,  3.05s/it] 45%|████▌     | 289/642 [16:06<17:47,  3.02s/it] 45%|████▌     | 290/642 [16:09<18:04,  3.08s/it]                                                  45%|████▌     | 290/642 [16:09<18:04,  3.08s/it] 45%|████▌     | 291/642 [16:13<19:05,  3.26s/it] 45%|████▌     | 292/642 [16:16<18:58,  3.25s/it] 46%|████▌     | 293/642 [16:19<19:30,  3.35s/it] 46%|████▌     | 294/642 [16:23<19:06,  3.30s/it] 46%|████▌     | 295/642 [16:26<18:53,  3.27s/it]                                                  46%|████▌     | 295/642 [16:26<18:53,  3.27s/it] 46%|████▌     | 296/642 [16:28<17:50,  3.09s/it] 46%|████▋     | 297/642 [16:31<17:20,  3.02s/it] 46%|████▋     | 298/642 [16:34<17:11,  3.00s/it] 47%|████▋     | 299/642 [16:37<16:55,  2.96s/it] 47%|████▋     | 300/642 [16:40<16:55,  2.97s/it]                                                  47%|████▋     | 300/642 [16:40<16:55,  2.97s/it] 47%|████▋     | 301/642 [16:43<17:13,  3.03s/it] 47%|████▋     | 302/642 [16:47<17:46,  3.14s/it] 47%|████▋     | 303/642 [16:49<16:43,  2.96s/it] 47%|████▋     | 304/642 [16:52<17:10,  3.05s/it] 48%|████▊     | 305/642 [16:56<17:09,  3.06s/it]                                                  48%|████▊     | 305/642 [16:56<17:09,  3.06s/it] 48%|████▊     | 306/642 [16:59<17:01,  3.04s/it] 48%|████▊     | 307/642 [17:01<16:33,  2.96s/it] 48%|████▊     | 308/642 [17:04<16:46,  3.01s/it] 48%|████▊     | 309/642 [17:07<16:49,  3.03s/it] 48%|████▊     | 310/642 [17:11<17:40,  3.20s/it]                                                  48%|████▊     | 310/642 [17:11<17:40,  3.20s/it] 48%|████▊     | 311/642 [17:15<18:21,  3.33s/it] 49%|████▊     | 312/642 [17:18<18:04,  3.29s/it] 49%|████▉     | 313/642 [17:21<17:37,  3.21s/it] 49%|████▉     | 314/642 [17:24<18:06,  3.31s/it] 49%|████▉     | 315/642 [17:28<17:39,  3.24s/it]                                                  49%|████▉     | 315/642 [17:28<17:39,  3.24s/it] 49%|████▉     | 316/642 [17:30<16:49,  3.10s/it] 49%|████▉     | 317/642 [17:33<16:31,  3.05s/it] 50%|████▉     | 318/642 [17:36<16:10,  3.00s/it] 50%|████▉     | 319/642 [17:39<16:17,  3.03s/it] 50%|████▉     | 320/642 [17:42<16:25,  3.06s/it]                                                  50%|████▉     | 320/642 [17:43<16:25,  3.06s/it] 50%|█████     | 321/642 [17:46<17:16,  3.23s/it] 50%|█████     | 322/642 [17:49<16:42,  3.13s/it] 50%|█████     | 323/642 [17:52<16:50,  3.17s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-323
Configuration saved in ./outputs/restem_6epoch/checkpoint-323/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-323/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-323/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-323/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-323/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 50%|█████     | 324/642 [18:47<1:39:34, 18.79s/it] 51%|█████     | 325/642 [18:50<1:14:05, 14.03s/it]                                                    51%|█████     | 325/642 [18:50<1:14:05, 14.03s/it] 51%|█████     | 326/642 [18:54<56:49, 10.79s/it]   51%|█████     | 327/642 [18:57<45:04,  8.59s/it] 51%|█████     | 328/642 [19:00<35:58,  6.87s/it] 51%|█████     | 329/642 [19:03<29:32,  5.66s/it] 51%|█████▏    | 330/642 [19:06<25:29,  4.90s/it]                                                  51%|█████▏    | 330/642 [19:06<25:29,  4.90s/it] 52%|█████▏    | 331/642 [19:09<22:39,  4.37s/it] 52%|█████▏    | 332/642 [19:12<20:32,  3.98s/it] 52%|█████▏    | 333/642 [19:15<19:24,  3.77s/it] 52%|█████▏    | 334/642 [19:18<17:55,  3.49s/it] 52%|█████▏    | 335/642 [19:21<16:37,  3.25s/it]                                                  52%|█████▏    | 335/642 [19:21<16:37,  3.25s/it] 52%|█████▏    | 336/642 [19:24<16:17,  3.19s/it] 52%|█████▏    | 337/642 [19:27<15:43,  3.10s/it] 53%|█████▎    | 338/642 [19:30<15:22,  3.04s/it] 53%|█████▎    | 339/642 [19:33<15:17,  3.03s/it] 53%|█████▎    | 340/642 [19:36<15:18,  3.04s/it]                                                  53%|█████▎    | 340/642 [19:36<15:18,  3.04s/it] 53%|█████▎    | 341/642 [19:39<15:22,  3.06s/it] 53%|█████▎    | 342/642 [19:42<15:35,  3.12s/it] 53%|█████▎    | 343/642 [19:45<15:48,  3.17s/it] 54%|█████▎    | 344/642 [19:49<16:21,  3.29s/it] 54%|█████▎    | 345/642 [19:52<16:15,  3.28s/it]                                                  54%|█████▎    | 345/642 [19:52<16:15,  3.28s/it] 54%|█████▍    | 346/642 [19:55<15:08,  3.07s/it] 54%|█████▍    | 347/642 [19:58<15:16,  3.11s/it] 54%|█████▍    | 348/642 [20:01<15:24,  3.14s/it] 54%|█████▍    | 349/642 [20:04<14:31,  2.98s/it] 55%|█████▍    | 350/642 [20:07<14:58,  3.08s/it]                                                  55%|█████▍    | 350/642 [20:07<14:58,  3.08s/it] 55%|█████▍    | 351/642 [20:10<14:25,  2.97s/it] 55%|█████▍    | 352/642 [20:13<14:51,  3.07s/it] 55%|█████▍    | 353/642 [20:16<14:49,  3.08s/it] 55%|█████▌    | 354/642 [20:20<15:29,  3.23s/it] 55%|█████▌    | 355/642 [20:23<15:20,  3.21s/it]                                                  55%|█████▌    | 355/642 [20:23<15:20,  3.21s/it] 55%|█████▌    | 356/642 [20:26<15:15,  3.20s/it] 56%|█████▌    | 357/642 [20:29<14:17,  3.01s/it] 56%|█████▌    | 358/642 [20:32<14:39,  3.10s/it] 56%|█████▌    | 359/642 [20:36<15:10,  3.22s/it] 56%|█████▌    | 360/642 [20:38<14:37,  3.11s/it]                                                  56%|█████▌    | 360/642 [20:39<14:37,  3.11s/it] 56%|█████▌    | 361/642 [20:41<14:10,  3.03s/it] 56%|█████▋    | 362/642 [20:44<14:19,  3.07s/it] 57%|█████▋    | 363/642 [20:48<14:37,  3.14s/it] 57%|█████▋    | 364/642 [20:51<14:14,  3.07s/it] 57%|█████▋    | 365/642 [20:54<15:08,  3.28s/it]                                                  57%|█████▋    | 365/642 [20:55<15:08,  3.28s/it] 57%|█████▋    | 366/642 [20:57<14:37,  3.18s/it] 57%|█████▋    | 367/642 [21:01<14:42,  3.21s/it] 57%|█████▋    | 368/642 [21:03<13:58,  3.06s/it] 57%|█████▋    | 369/642 [21:06<13:31,  2.97s/it] 58%|█████▊    | 370/642 [21:09<13:41,  3.02s/it]                                                  58%|█████▊    | 370/642 [21:09<13:41,  3.02s/it] 58%|█████▊    | 371/642 [21:13<14:18,  3.17s/it] 58%|█████▊    | 372/642 [21:16<13:59,  3.11s/it] 58%|█████▊    | 373/642 [21:19<14:21,  3.20s/it] 58%|█████▊    | 374/642 [21:22<14:02,  3.14s/it] 58%|█████▊    | 375/642 [21:25<14:13,  3.20s/it]                                                  58%|█████▊    | 375/642 [21:26<14:13,  3.20s/it] 59%|█████▊    | 376/642 [21:29<14:50,  3.35s/it] 59%|█████▊    | 377/642 [21:32<14:21,  3.25s/it] 59%|█████▉    | 378/642 [21:35<13:48,  3.14s/it] 59%|█████▉    | 379/642 [21:38<13:39,  3.12s/it] 59%|█████▉    | 380/642 [21:41<13:29,  3.09s/it]                                                  59%|█████▉    | 380/642 [21:41<13:29,  3.09s/it] 59%|█████▉    | 381/642 [21:44<13:30,  3.11s/it] 60%|█████▉    | 382/642 [21:47<13:34,  3.13s/it] 60%|█████▉    | 383/642 [21:51<13:42,  3.18s/it] 60%|█████▉    | 384/642 [21:53<12:58,  3.02s/it] 60%|█████▉    | 385/642 [21:57<13:27,  3.14s/it]                                                  60%|█████▉    | 385/642 [21:57<13:27,  3.14s/it] 60%|██████    | 386/642 [22:00<12:50,  3.01s/it] 60%|██████    | 387/642 [22:03<12:45,  3.00s/it] 60%|██████    | 388/642 [22:06<13:06,  3.10s/it] 61%|██████    | 389/642 [22:09<13:20,  3.16s/it] 61%|██████    | 390/642 [22:12<13:26,  3.20s/it]                                                  61%|██████    | 390/642 [22:13<13:26,  3.20s/it] 61%|██████    | 391/642 [22:16<13:32,  3.24s/it] 61%|██████    | 392/642 [22:19<12:59,  3.12s/it] 61%|██████    | 393/642 [22:21<12:13,  2.95s/it] 61%|██████▏   | 394/642 [22:25<12:50,  3.11s/it] 62%|██████▏   | 395/642 [22:28<12:40,  3.08s/it]                                                  62%|██████▏   | 395/642 [22:28<12:40,  3.08s/it] 62%|██████▏   | 396/642 [22:31<12:58,  3.16s/it] 62%|██████▏   | 397/642 [22:34<12:29,  3.06s/it] 62%|██████▏   | 398/642 [22:37<12:17,  3.02s/it] 62%|██████▏   | 399/642 [22:40<12:21,  3.05s/it] 62%|██████▏   | 400/642 [22:43<12:19,  3.06s/it]                                                  62%|██████▏   | 400/642 [22:43<12:19,  3.06s/it] 62%|██████▏   | 401/642 [22:46<11:57,  2.98s/it] 63%|██████▎   | 402/642 [22:49<12:07,  3.03s/it] 63%|██████▎   | 403/642 [22:52<11:53,  2.99s/it] 63%|██████▎   | 404/642 [22:55<12:07,  3.06s/it] 63%|██████▎   | 405/642 [22:58<12:02,  3.05s/it]                                                  63%|██████▎   | 405/642 [22:58<12:02,  3.05s/it] 63%|██████▎   | 406/642 [23:01<12:10,  3.09s/it] 63%|██████▎   | 407/642 [23:05<12:45,  3.26s/it] 64%|██████▎   | 408/642 [23:08<12:19,  3.16s/it] 64%|██████▎   | 409/642 [23:11<12:41,  3.27s/it] 64%|██████▍   | 410/642 [23:14<11:57,  3.09s/it]                                                  64%|██████▍   | 410/642 [23:14<11:57,  3.09s/it] 64%|██████▍   | 411/642 [23:17<12:02,  3.13s/it] 64%|██████▍   | 412/642 [23:20<12:01,  3.14s/it] 64%|██████▍   | 413/642 [23:24<11:58,  3.14s/it] 64%|██████▍   | 414/642 [23:27<11:59,  3.16s/it] 65%|██████▍   | 415/642 [23:30<12:06,  3.20s/it]                                                  65%|██████▍   | 415/642 [23:30<12:06,  3.20s/it] 65%|██████▍   | 416/642 [23:33<11:56,  3.17s/it] 65%|██████▍   | 417/642 [23:36<11:50,  3.16s/it] 65%|██████▌   | 418/642 [23:39<11:33,  3.10s/it] 65%|██████▌   | 419/642 [23:42<11:25,  3.07s/it] 65%|██████▌   | 420/642 [23:45<11:18,  3.06s/it]                                                  65%|██████▌   | 420/642 [23:45<11:18,  3.06s/it] 66%|██████▌   | 421/642 [23:48<11:15,  3.06s/it] 66%|██████▌   | 422/642 [23:51<11:03,  3.02s/it] 66%|██████▌   | 423/642 [23:54<10:51,  2.97s/it] 66%|██████▌   | 424/642 [23:57<10:44,  2.96s/it] 66%|██████▌   | 425/642 [24:00<10:32,  2.92s/it]                                                  66%|██████▌   | 425/642 [24:00<10:32,  2.92s/it] 66%|██████▋   | 426/642 [24:03<10:37,  2.95s/it] 67%|██████▋   | 427/642 [24:06<11:11,  3.12s/it] 67%|██████▋   | 428/642 [24:10<11:47,  3.31s/it] 67%|██████▋   | 429/642 [24:13<11:06,  3.13s/it] 67%|██████▋   | 430/642 [24:16<10:50,  3.07s/it]                                                  67%|██████▋   | 430/642 [24:16<10:50,  3.07s/it] 67%|██████▋   | 431/642 [24:19<10:45,  3.06s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-431
Configuration saved in ./outputs/restem_6epoch/checkpoint-431/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-431/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-431/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-431/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-431/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 67%|██████▋   | 432/642 [25:15<1:07:00, 19.15s/it] 67%|██████▋   | 433/642 [25:18<49:42, 14.27s/it]   68%|██████▊   | 434/642 [25:21<37:35, 10.84s/it] 68%|██████▊   | 435/642 [25:24<29:22,  8.51s/it]                                                  68%|██████▊   | 435/642 [25:24<29:22,  8.51s/it] 68%|██████▊   | 436/642 [25:27<23:19,  6.79s/it] 68%|██████▊   | 437/642 [25:30<19:11,  5.62s/it] 68%|██████▊   | 438/642 [25:33<16:34,  4.88s/it] 68%|██████▊   | 439/642 [25:36<14:28,  4.28s/it] 69%|██████▊   | 440/642 [25:39<13:25,  3.99s/it]                                                 {'loss': 2.4879, 'grad_norm': 304.0, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.05}
{'loss': 2.2869, 'grad_norm': 58.5, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.09}
{'loss': 1.8801, 'grad_norm': 208.0, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.14}
{'loss': 1.4544, 'grad_norm': 7.40625, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.19}
{'loss': 1.1734, 'grad_norm': 5.71875, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.23}
{'loss': 1.006, 'grad_norm': 4.65625, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.28}
{'loss': 0.9744, 'grad_norm': 3.984375, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.32}
{'loss': 0.9372, 'grad_norm': 4.34375, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.37}
{'loss': 0.8942, 'grad_norm': 3.6875, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.42}
{'loss': 0.8729, 'grad_norm': 3.6875, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.46}
{'loss': 0.8978, 'grad_norm': 3.8125, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.51}
{'loss': 0.8524, 'grad_norm': 3.546875, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.56}
{'loss': 0.8231, 'grad_norm': 3.5625, 'learning_rate': 2e-05, 'epoch': 0.6}
{'loss': 0.8315, 'grad_norm': 3.28125, 'learning_rate': 1.9996294632312766e-05, 'epoch': 0.65}
{'loss': 0.8262, 'grad_norm': 3.65625, 'learning_rate': 1.9985181275201e-05, 'epoch': 0.7}
{'loss': 0.8193, 'grad_norm': 3.109375, 'learning_rate': 1.9966668164479567e-05, 'epoch': 0.74}
{'loss': 0.8732, 'grad_norm': 3.28125, 'learning_rate': 1.9940769019724926e-05, 'epoch': 0.79}
{'loss': 0.8356, 'grad_norm': 3.03125, 'learning_rate': 1.9907503034107893e-05, 'epoch': 0.84}
{'loss': 0.8692, 'grad_norm': 3.0625, 'learning_rate': 1.9866894860170104e-05, 'epoch': 0.88}
{'loss': 0.8007, 'grad_norm': 2.984375, 'learning_rate': 1.9818974591554668e-05, 'epoch': 0.93}
{'loss': 0.8366, 'grad_norm': 3.296875, 'learning_rate': 1.9763777740704572e-05, 'epoch': 0.97}
{'loss': 0.8049, 'grad_norm': 2.625, 'learning_rate': 1.970134521254532e-05, 'epoch': 1.02}
{'loss': 0.6126, 'grad_norm': 2.921875, 'learning_rate': 1.9631723274171412e-05, 'epoch': 1.07}
{'loss': 0.6394, 'grad_norm': 2.96875, 'learning_rate': 1.9554963520559003e-05, 'epoch': 1.11}
{'loss': 0.6416, 'grad_norm': 3.421875, 'learning_rate': 1.9471122836330236e-05, 'epoch': 1.16}
{'loss': 0.6129, 'grad_norm': 3.40625, 'learning_rate': 1.9380263353597553e-05, 'epoch': 1.21}
{'loss': 0.6533, 'grad_norm': 3.359375, 'learning_rate': 1.9282452405919235e-05, 'epoch': 1.25}
{'loss': 0.6333, 'grad_norm': 3.515625, 'learning_rate': 1.9177762478400276e-05, 'epoch': 1.3}
{'loss': 0.6426, 'grad_norm': 2.921875, 'learning_rate': 1.9066271153975602e-05, 'epoch': 1.35}
{'loss': 0.6492, 'grad_norm': 3.421875, 'learning_rate': 1.8948061055915395e-05, 'epoch': 1.39}
{'loss': 0.6052, 'grad_norm': 3.09375, 'learning_rate': 1.882321978659519e-05, 'epoch': 1.44}
{'loss': 0.6471, 'grad_norm': 3.15625, 'learning_rate': 1.869183986257606e-05, 'epoch': 1.48}
{'loss': 0.6229, 'grad_norm': 3.15625, 'learning_rate': 1.8554018646043045e-05, 'epoch': 1.53}
{'loss': 0.6153, 'grad_norm': 3.46875, 'learning_rate': 1.840985827265262e-05, 'epoch': 1.58}
{'loss': 0.6302, 'grad_norm': 3.1875, 'learning_rate': 1.825946557584265e-05, 'epoch': 1.62}
{'loss': 0.6296, 'grad_norm': 3.421875, 'learning_rate': 1.810295200766097e-05, 'epoch': 1.67}
{'loss': 0.6141, 'grad_norm': 3.328125, 'learning_rate': 1.794043355617121e-05, 'epoch': 1.72}
{'loss': 0.6288, 'grad_norm': 3.3125, 'learning_rate': 1.7772030659497112e-05, 'epoch': 1.76}
{'loss': 0.6376, 'grad_norm': 2.984375, 'learning_rate': 1.7597868116569036e-05, 'epoch': 1.81}
{'loss': 0.6139, 'grad_norm': 3.25, 'learning_rate': 1.7418074994638752e-05, 'epoch': 1.86}
{'loss': 0.6259, 'grad_norm': 3.609375, 'learning_rate': 1.7232784533631148e-05, 'epoch': 1.9}
{'loss': 0.6429, 'grad_norm': 2.9375, 'learning_rate': 1.7042134047403613e-05, 'epoch': 1.95}
{'loss': 0.6532, 'grad_norm': 3.703125, 'learning_rate': 1.684626482198639e-05, 'epoch': 2.0}
{'loss': 0.4533, 'grad_norm': 3.71875, 'learning_rate': 1.6645322010879242e-05, 'epoch': 2.04}
{'loss': 0.3677, 'grad_norm': 4.71875, 'learning_rate': 1.6439454527482014e-05, 'epoch': 2.09}
{'loss': 0.3657, 'grad_norm': 3.703125, 'learning_rate': 1.6228814934738873e-05, 'epoch': 2.13}
{'loss': 0.3359, 'grad_norm': 4.3125, 'learning_rate': 1.6013559332077945e-05, 'epoch': 2.18}
{'loss': 0.3438, 'grad_norm': 5.3125, 'learning_rate': 1.5793847239730148e-05, 'epoch': 2.23}
{'loss': 0.3437, 'grad_norm': 4.4375, 'learning_rate': 1.5569841480512972e-05, 'epoch': 2.27}
{'loss': 0.3474, 'grad_norm': 4.09375, 'learning_rate': 1.534170805916681e-05, 'epoch': 2.32}
{'loss': 0.3529, 'grad_norm': 4.65625, 'learning_rate': 1.510961603933324e-05, 'epoch': 2.37}
{'loss': 0.3486, 'grad_norm': 3.96875, 'learning_rate': 1.4873737418266398e-05, 'epoch': 2.41}
{'loss': 0.3345, 'grad_norm': 4.15625, 'learning_rate': 1.4634246999370415e-05, 'epoch': 2.46}
{'loss': 0.3498, 'grad_norm': 4.125, 'learning_rate': 1.4391322262657206e-05, 'epoch': 2.51}
{'loss': 0.331, 'grad_norm': 3.71875, 'learning_rate': 1.4145143233220741e-05, 'epoch': 2.55}
{'loss': 0.3499, 'grad_norm': 4.28125, 'learning_rate': 1.3895892347825205e-05, 'epoch': 2.6}
{'loss': 0.348, 'grad_norm': 4.78125, 'learning_rate': 1.3643754319705956e-05, 'epoch': 2.65}
{'loss': 0.3527, 'grad_norm': 4.03125, 'learning_rate': 1.3388916001683412e-05, 'epoch': 2.69}
{'loss': 0.3207, 'grad_norm': 4.0625, 'learning_rate': 1.3131566247691387e-05, 'epoch': 2.74}
{'loss': 0.3458, 'grad_norm': 4.25, 'learning_rate': 1.2871895772822442e-05, 'epoch': 2.78}
{'loss': 0.3501, 'grad_norm': 4.0625, 'learning_rate': 1.261009701199395e-05, 'epoch': 2.83}
{'loss': 0.3583, 'grad_norm': 3.578125, 'learning_rate': 1.2346363977339698e-05, 'epoch': 2.88}
{'loss': 0.3328, 'grad_norm': 4.03125, 'learning_rate': 1.208089211443262e-05, 'epoch': 2.92}
{'loss': 0.3365, 'grad_norm': 3.890625, 'learning_rate': 1.1813878157445253e-05, 'epoch': 2.97}
{'loss': 0.3156, 'grad_norm': 3.53125, 'learning_rate': 1.1545519983355255e-05, 'epoch': 3.02}
{'loss': 0.1769, 'grad_norm': 3.90625, 'learning_rate': 1.1276016465303989e-05, 'epoch': 3.06}
{'loss': 0.1737, 'grad_norm': 5.78125, 'learning_rate': 1.1005567325216946e-05, 'epoch': 3.11}
{'loss': 0.165, 'grad_norm': 4.28125, 'learning_rate': 1.0734372985795062e-05, 'epoch': 3.16}
{'loss': 0.1701, 'grad_norm': 3.546875, 'learning_rate': 1.0462634421986786e-05, 'epoch': 3.2}
{'loss': 0.1707, 'grad_norm': 4.46875, 'learning_rate': 1.0190553012050868e-05, 'epoch': 3.25}
{'loss': 0.1603, 'grad_norm': 4.25, 'learning_rate': 9.918330388320235e-06, 'epoch': 3.29}
{'loss': 0.1662, 'grad_norm': 4.0625, 'learning_rate': 9.646168287777633e-06, 'epoch': 3.34}
{'loss': 0.159, 'grad_norm': 4.46875, 'learning_rate': 9.374268402553665e-06, 'epoch': 3.39}
{'loss': 0.163, 'grad_norm': 3.984375, 'learning_rate': 9.102832230458115e-06, 'epoch': 3.43}
{'loss': 0.1591, 'grad_norm': 4.09375, 'learning_rate': 8.83206092565522e-06, 'epoch': 3.48}
{'loss': 0.1706, 'grad_norm': 4.34375, 'learning_rate': 8.562155149593673e-06, 'epoch': 3.53}
{'loss': 0.1595, 'grad_norm': 4.4375, 'learning_rate': 8.293314922301715e-06, 'epoch': 3.57}
{'loss': 0.1637, 'grad_norm': 4.03125, 'learning_rate': 8.025739474157595e-06, 'epoch': 3.62}
{'loss': 0.1665, 'grad_norm': 3.828125, 'learning_rate': 7.759627098245207e-06, 'epoch': 3.67}
{'loss': 0.167, 'grad_norm': 3.953125, 'learning_rate': 7.49517500340432e-06, 'epoch': 3.71}
{'loss': 0.1533, 'grad_norm': 3.78125, 'learning_rate': 7.232579168084344e-06, 'epoch': 3.76}
{'loss': 0.1651, 'grad_norm': 4.3125, 'learning_rate': 6.972034195109885e-06, 'epoch': 3.81}
{'loss': 0.1673, 'grad_norm': 3.640625, 'learning_rate': 6.713733167465723e-06, 'epoch': 3.85}
{'loss': 0.1576, 'grad_norm': 4.125, 'learning_rate': 6.4578675052081395e-06, 'epoch': 3.9}
{'loss': 0.1688, 'grad_norm': 3.96875, 'learning_rate': 6.204626823608584e-06, 'epoch': 3.94}
{'loss': 0.1571, 'grad_norm': 3.78125, 'learning_rate': 5.954198792634782e-06, 'epoch': 3.99}
{'loss': 0.1248, 'grad_norm': 2.546875, 'learning_rate': 5.706768997873533e-06, 'epoch': 4.04}
 69%|██████▊   | 440/642 [25:39<13:25,  3.99s/it] 69%|██████▊   | 441/642 [25:43<12:43,  3.80s/it] 69%|██████▉   | 442/642 [25:46<12:04,  3.62s/it] 69%|██████▉   | 443/642 [25:49<11:22,  3.43s/it] 69%|██████▉   | 444/642 [25:52<11:03,  3.35s/it] 69%|██████▉   | 445/642 [25:55<10:38,  3.24s/it]                                                  69%|██████▉   | 445/642 [25:55<10:38,  3.24s/it] 69%|██████▉   | 446/642 [25:58<10:06,  3.10s/it] 70%|██████▉   | 447/642 [26:01<10:06,  3.11s/it] 70%|██████▉   | 448/642 [26:04<10:07,  3.13s/it] 70%|██████▉   | 449/642 [26:07<09:23,  2.92s/it] 70%|███████   | 450/642 [26:09<09:08,  2.86s/it]                                                  70%|███████   | 450/642 [26:09<09:08,  2.86s/it] 70%|███████   | 451/642 [26:12<08:48,  2.77s/it] 70%|███████   | 452/642 [26:15<09:02,  2.85s/it] 71%|███████   | 453/642 [26:18<09:38,  3.06s/it] 71%|███████   | 454/642 [26:22<09:56,  3.17s/it] 71%|███████   | 455/642 [26:25<09:29,  3.04s/it]                                                  71%|███████   | 455/642 [26:25<09:29,  3.04s/it] 71%|███████   | 456/642 [26:28<09:46,  3.15s/it] 71%|███████   | 457/642 [26:31<09:38,  3.13s/it] 71%|███████▏  | 458/642 [26:34<09:32,  3.11s/it] 71%|███████▏  | 459/642 [26:38<09:48,  3.22s/it] 72%|███████▏  | 460/642 [26:41<09:38,  3.18s/it]                                                  72%|███████▏  | 460/642 [26:41<09:38,  3.18s/it] 72%|███████▏  | 461/642 [26:44<09:33,  3.17s/it] 72%|███████▏  | 462/642 [26:47<09:21,  3.12s/it] 72%|███████▏  | 463/642 [26:50<09:09,  3.07s/it] 72%|███████▏  | 464/642 [26:53<08:57,  3.02s/it] 72%|███████▏  | 465/642 [26:56<09:01,  3.06s/it]                                                  72%|███████▏  | 465/642 [26:56<09:01,  3.06s/it] 73%|███████▎  | 466/642 [26:59<08:55,  3.04s/it] 73%|███████▎  | 467/642 [27:02<08:48,  3.02s/it] 73%|███████▎  | 468/642 [27:05<08:57,  3.09s/it] 73%|███████▎  | 469/642 [27:08<08:50,  3.07s/it] 73%|███████▎  | 470/642 [27:11<08:38,  3.01s/it]                                                  73%|███████▎  | 470/642 [27:11<08:38,  3.01s/it] 73%|███████▎  | 471/642 [27:14<08:17,  2.91s/it] 74%|███████▎  | 472/642 [27:17<08:18,  2.93s/it] 74%|███████▎  | 473/642 [27:19<08:13,  2.92s/it] 74%|███████▍  | 474/642 [27:23<08:35,  3.07s/it] 74%|███████▍  | 475/642 [27:26<08:34,  3.08s/it]                                                  74%|███████▍  | 475/642 [27:26<08:34,  3.08s/it] 74%|███████▍  | 476/642 [27:29<08:25,  3.04s/it] 74%|███████▍  | 477/642 [27:32<08:22,  3.05s/it] 74%|███████▍  | 478/642 [27:35<08:05,  2.96s/it] 75%|███████▍  | 479/642 [27:38<08:26,  3.11s/it] 75%|███████▍  | 480/642 [27:42<08:47,  3.26s/it]                                                  75%|███████▍  | 480/642 [27:42<08:47,  3.26s/it] 75%|███████▍  | 481/642 [27:45<08:43,  3.25s/it] 75%|███████▌  | 482/642 [27:48<08:31,  3.20s/it] 75%|███████▌  | 483/642 [27:51<08:17,  3.13s/it] 75%|███████▌  | 484/642 [27:54<07:55,  3.01s/it] 76%|███████▌  | 485/642 [27:57<07:44,  2.96s/it]                                                  76%|███████▌  | 485/642 [27:57<07:44,  2.96s/it] 76%|███████▌  | 486/642 [28:00<07:59,  3.07s/it] 76%|███████▌  | 487/642 [28:03<07:37,  2.95s/it] 76%|███████▌  | 488/642 [28:06<07:42,  3.00s/it] 76%|███████▌  | 489/642 [28:09<07:55,  3.11s/it] 76%|███████▋  | 490/642 [28:12<07:35,  3.00s/it]                                                  76%|███████▋  | 490/642 [28:12<07:35,  3.00s/it] 76%|███████▋  | 491/642 [28:15<07:20,  2.92s/it] 77%|███████▋  | 492/642 [28:18<07:20,  2.94s/it] 77%|███████▋  | 493/642 [28:21<07:17,  2.93s/it] 77%|███████▋  | 494/642 [28:24<07:19,  2.97s/it] 77%|███████▋  | 495/642 [28:27<07:37,  3.11s/it]                                                  77%|███████▋  | 495/642 [28:27<07:37,  3.11s/it] 77%|███████▋  | 496/642 [28:30<07:30,  3.09s/it] 77%|███████▋  | 497/642 [28:34<07:53,  3.27s/it] 78%|███████▊  | 498/642 [28:37<07:59,  3.33s/it] 78%|███████▊  | 499/642 [28:40<07:39,  3.22s/it] 78%|███████▊  | 500/642 [28:44<07:57,  3.36s/it]                                                  78%|███████▊  | 500/642 [28:44<07:57,  3.36s/it] 78%|███████▊  | 501/642 [28:47<07:44,  3.29s/it] 78%|███████▊  | 502/642 [28:50<07:26,  3.19s/it] 78%|███████▊  | 503/642 [28:53<07:25,  3.20s/it] 79%|███████▊  | 504/642 [28:56<07:25,  3.22s/it] 79%|███████▊  | 505/642 [28:59<07:10,  3.14s/it]                                                  79%|███████▊  | 505/642 [29:00<07:10,  3.14s/it] 79%|███████▉  | 506/642 [29:02<06:46,  2.99s/it] 79%|███████▉  | 507/642 [29:05<06:53,  3.06s/it] 79%|███████▉  | 508/642 [29:09<07:01,  3.14s/it] 79%|███████▉  | 509/642 [29:12<06:54,  3.12s/it] 79%|███████▉  | 510/642 [29:15<07:11,  3.27s/it]                                                  79%|███████▉  | 510/642 [29:15<07:11,  3.27s/it] 80%|███████▉  | 511/642 [29:18<06:54,  3.17s/it] 80%|███████▉  | 512/642 [29:21<06:47,  3.13s/it] 80%|███████▉  | 513/642 [29:25<06:53,  3.20s/it] 80%|████████  | 514/642 [29:28<06:55,  3.24s/it] 80%|████████  | 515/642 [29:31<06:44,  3.18s/it]                                                  80%|████████  | 515/642 [29:31<06:44,  3.18s/it] 80%|████████  | 516/642 [29:34<06:43,  3.20s/it] 81%|████████  | 517/642 [29:37<06:18,  3.03s/it] 81%|████████  | 518/642 [29:40<06:25,  3.11s/it] 81%|████████  | 519/642 [29:43<06:24,  3.13s/it] 81%|████████  | 520/642 [29:46<06:20,  3.12s/it]                                                  81%|████████  | 520/642 [29:47<06:20,  3.12s/it] 81%|████████  | 521/642 [29:49<06:06,  3.03s/it] 81%|████████▏ | 522/642 [29:53<06:15,  3.13s/it] 81%|████████▏ | 523/642 [29:56<06:03,  3.06s/it] 82%|████████▏ | 524/642 [29:59<06:11,  3.15s/it] 82%|████████▏ | 525/642 [30:02<06:01,  3.09s/it]                                                  82%|████████▏ | 525/642 [30:02<06:01,  3.09s/it] 82%|████████▏ | 526/642 [30:05<06:14,  3.23s/it] 82%|████████▏ | 527/642 [30:08<06:04,  3.17s/it] 82%|████████▏ | 528/642 [30:11<05:47,  3.04s/it] 82%|████████▏ | 529/642 [30:14<05:51,  3.11s/it] 83%|████████▎ | 530/642 [30:18<05:55,  3.18s/it]                                                  83%|████████▎ | 530/642 [30:18<05:55,  3.18s/it] 83%|████████▎ | 531/642 [30:21<06:03,  3.28s/it] 83%|████████▎ | 532/642 [30:24<05:54,  3.22s/it] 83%|████████▎ | 533/642 [30:28<05:48,  3.19s/it] 83%|████████▎ | 534/642 [30:31<05:47,  3.22s/it] 83%|████████▎ | 535/642 [30:34<05:55,  3.33s/it]                                                  83%|████████▎ | 535/642 [30:35<05:55,  3.33s/it] 83%|████████▎ | 536/642 [30:37<05:35,  3.17s/it] 84%|████████▎ | 537/642 [30:40<05:23,  3.08s/it] 84%|████████▍ | 538/642 [30:43<05:10,  2.98s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-538
Configuration saved in ./outputs/restem_6epoch/checkpoint-538/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-538/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-538/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-538/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-538/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
/home/cyc2202/anaconda3/envs/restem/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 84%|████████▍ | 539/642 [31:25<25:14, 14.70s/it] 84%|████████▍ | 540/642 [31:28<18:54, 11.12s/it]                                                  84%|████████▍ | 540/642 [31:28<18:54, 11.12s/it] 84%|████████▍ | 541/642 [31:31<14:34,  8.66s/it] 84%|████████▍ | 542/642 [31:33<11:33,  6.93s/it] 85%|████████▍ | 543/642 [31:36<09:23,  5.70s/it] 85%|████████▍ | 544/642 [31:39<07:57,  4.88s/it] 85%|████████▍ | 545/642 [31:42<06:56,  4.29s/it]                                                  85%|████████▍ | 545/642 [31:42<06:56,  4.29s/it] 85%|████████▌ | 546/642 [31:45<06:20,  3.96s/it] 85%|████████▌ | 547/642 [31:48<05:49,  3.68s/it] 85%|████████▌ | 548/642 [31:52<05:33,  3.54s/it] 86%|████████▌ | 549/642 [31:55<05:16,  3.40s/it] 86%|████████▌ | 550/642 [31:58<05:09,  3.36s/it]                                                  86%|████████▌ | 550/642 [31:58<05:09,  3.36s/it] 86%|████████▌ | 551/642 [32:02<05:15,  3.47s/it] 86%|████████▌ | 552/642 [32:05<05:04,  3.39s/it] 86%|████████▌ | 553/642 [32:08<04:51,  3.28s/it] 86%|████████▋ | 554/642 [32:11<04:43,  3.22s/it] 86%|████████▋ | 555/642 [32:14<04:29,  3.10s/it]                                                  86%|████████▋ | 555/642 [32:14<04:29,  3.10s/it] 87%|████████▋ | 556/642 [32:17<04:31,  3.16s/it] 87%|████████▋ | 557/642 [32:20<04:20,  3.06s/it] 87%|████████▋ | 558/642 [32:23<04:24,  3.15s/it] 87%|████████▋ | 559/642 [32:26<04:16,  3.09s/it] 87%|████████▋ | 560/642 [32:29<04:16,  3.13s/it]                                                  87%|████████▋ | 560/642 [32:30<04:16,  3.13s/it] 87%|████████▋ | 561/642 [32:33<04:13,  3.13s/it] 88%|████████▊ | 562/642 [32:36<04:09,  3.11s/it] 88%|████████▊ | 563/642 [32:39<04:12,  3.19s/it] 88%|████████▊ | 564/642 [32:42<03:58,  3.06s/it] 88%|████████▊ | 565/642 [32:45<03:53,  3.04s/it]                                                  88%|████████▊ | 565/642 [32:45<03:53,  3.04s/it] 88%|████████▊ | 566/642 [32:47<03:42,  2.92s/it] 88%|████████▊ | 567/642 [32:50<03:42,  2.96s/it] 88%|████████▊ | 568/642 [32:54<03:42,  3.00s/it] 89%|████████▊ | 569/642 [32:56<03:31,  2.90s/it] 89%|████████▉ | 570/642 [32:59<03:33,  2.96s/it]                                                  89%|████████▉ | 570/642 [32:59<03:33,  2.96s/it] 89%|████████▉ | 571/642 [33:02<03:25,  2.90s/it] 89%|████████▉ | 572/642 [33:05<03:25,  2.93s/it] 89%|████████▉ | 573/642 [33:09<03:36,  3.14s/it] 89%|████████▉ | 574/642 [33:12<03:32,  3.12s/it] 90%|████████▉ | 575/642 [33:14<03:20,  2.99s/it]                                                  90%|████████▉ | 575/642 [33:15<03:20,  2.99s/it] 90%|████████▉ | 576/642 [33:18<03:23,  3.08s/it] 90%|████████▉ | 577/642 [33:21<03:23,  3.14s/it] 90%|█████████ | 578/642 [33:24<03:24,  3.20s/it] 90%|█████████ | 579/642 [33:27<03:19,  3.17s/it] 90%|█████████ | 580/642 [33:30<03:12,  3.11s/it]                                                  90%|█████████ | 580/642 [33:31<03:12,  3.11s/it] 90%|█████████ | 581/642 [33:33<03:05,  3.04s/it] 91%|█████████ | 582/642 [33:36<03:00,  3.01s/it] 91%|█████████ | 583/642 [33:39<02:56,  3.00s/it] 91%|█████████ | 584/642 [33:42<02:56,  3.05s/it] 91%|█████████ | 585/642 [33:45<02:52,  3.03s/it]                                                  91%|█████████ | 585/642 [33:46<02:52,  3.03s/it] 91%|█████████▏| 586/642 [33:49<02:53,  3.09s/it] 91%|█████████▏| 587/642 [33:52<02:48,  3.07s/it] 92%|█████████▏| 588/642 [33:55<02:42,  3.02s/it] 92%|█████████▏| 589/642 [33:58<02:45,  3.12s/it] 92%|█████████▏| 590/642 [34:01<02:38,  3.04s/it]                                                  92%|█████████▏| 590/642 [34:01<02:38,  3.04s/it] 92%|█████████▏| 591/642 [34:04<02:38,  3.11s/it] 92%|█████████▏| 592/642 [34:07<02:36,  3.13s/it] 92%|█████████▏| 593/642 [34:10<02:29,  3.05s/it] 93%|█████████▎| 594/642 [34:13<02:27,  3.08s/it] 93%|█████████▎| 595/642 [34:16<02:27,  3.13s/it]                                                  93%|█████████▎| 595/642 [34:17<02:27,  3.13s/it] 93%|█████████▎| 596/642 [34:20<02:23,  3.13s/it] 93%|█████████▎| 597/642 [34:24<02:32,  3.38s/it] 93%|█████████▎| 598/642 [34:26<02:21,  3.21s/it] 93%|█████████▎| 599/642 [34:29<02:16,  3.18s/it] 93%|█████████▎| 600/642 [34:32<02:11,  3.12s/it]                                                  93%|█████████▎| 600/642 [34:33<02:11,  3.12s/it] 94%|█████████▎| 601/642 [34:36<02:10,  3.18s/it] 94%|█████████▍| 602/642 [34:39<02:04,  3.11s/it] 94%|█████████▍| 603/642 [34:41<01:55,  2.97s/it] 94%|█████████▍| 604/642 [34:45<01:58,  3.12s/it] 94%|█████████▍| 605/642 [34:48<01:55,  3.11s/it]                                                  94%|█████████▍| 605/642 [34:48<01:55,  3.11s/it] 94%|█████████▍| 606/642 [34:51<01:55,  3.21s/it] 95%|█████████▍| 607/642 [34:54<01:49,  3.13s/it] 95%|█████████▍| 608/642 [34:57<01:45,  3.09s/it] 95%|█████████▍| 609/642 [35:00<01:38,  2.99s/it] 95%|█████████▌| 610/642 [35:03<01:35,  2.98s/it]                                                  95%|█████████▌| 610/642 [35:03<01:35,  2.98s/it] 95%|█████████▌| 611/642 [35:06<01:36,  3.12s/it] 95%|█████████▌| 612/642 [35:09<01:31,  3.04s/it] 95%|█████████▌| 613/642 [35:12<01:25,  2.95s/it] 96%|█████████▌| 614/642 [35:15<01:22,  2.95s/it] 96%|█████████▌| 615/642 [35:18<01:22,  3.07s/it]                                                  96%|█████████▌| 615/642 [35:19<01:22,  3.07s/it] 96%|█████████▌| 616/642 [35:21<01:19,  3.06s/it] 96%|█████████▌| 617/642 [35:25<01:17,  3.09s/it] 96%|█████████▋| 618/642 [35:28<01:15,  3.14s/it] 96%|█████████▋| 619/642 [35:31<01:13,  3.18s/it] 97%|█████████▋| 620/642 [35:34<01:07,  3.07s/it]                                                  97%|█████████▋| 620/642 [35:34<01:07,  3.07s/it] 97%|█████████▋| 621/642 [35:37<01:05,  3.10s/it] 97%|█████████▋| 622/642 [35:40<01:01,  3.06s/it] 97%|█████████▋| 623/642 [35:43<00:57,  3.00s/it] 97%|█████████▋| 624/642 [35:46<00:55,  3.08s/it] 97%|█████████▋| 625/642 [35:50<00:53,  3.17s/it]                                                  97%|█████████▋| 625/642 [35:50<00:53,  3.17s/it] 98%|█████████▊| 626/642 [35:53<00:51,  3.21s/it] 98%|█████████▊| 627/642 [35:56<00:47,  3.19s/it] 98%|█████████▊| 628/642 [36:00<00:47,  3.37s/it] 98%|█████████▊| 629/642 [36:03<00:42,  3.26s/it] 98%|█████████▊| 630/642 [36:06<00:38,  3.21s/it]                                                  98%|█████████▊| 630/642 [36:06<00:38,  3.21s/it] 98%|█████████▊| 631/642 [36:09<00:34,  3.16s/it] 98%|█████████▊| 632/642 [36:12<00:30,  3.08s/it] 99%|█████████▊| 633/642 [36:15<00:27,  3.08s/it] 99%|█████████▉| 634/642 [36:18<00:23,  2.99s/it] 99%|█████████▉| 635/642 [36:21<00:21,  3.01s/it]                                                  99%|█████████▉| 635/642 [36:21<00:21,  3.01s/it] 99%|█████████▉| 636/642 [36:24<00:18,  3.05s/it] 99%|█████████▉| 637/642 [36:27<00:15,  3.00s/it] 99%|█████████▉| 638/642 [36:29<00:11,  2.92s/it]100%|█████████▉| 639/642 [36:33<00:09,  3.05s/it]100%|█████████▉| 640/642 [36:36<00:06,  3.16s/it]                                                 100%|█████████▉| 640/642 [36:36<00:06,  3.16s/it]100%|█████████▉| 641/642 [36:40<00:03,  3.22s/it]100%|██████████| 642/642 [36:43<00:00,  3.15s/it]Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-642
Configuration saved in ./outputs/restem_6epoch/checkpoint-642/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-642/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-642/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-642/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-642/special_tokens_map.json
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
Saving model checkpoint to ./outputs/restem_6epoch/checkpoint-642
Configuration saved in ./outputs/restem_6epoch/checkpoint-642/config.json
Configuration saved in ./outputs/restem_6epoch/checkpoint-642/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/checkpoint-642/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/checkpoint-642/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/checkpoint-642/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 642/642 [38:34<00:00,  3.15s/it]100%|██████████| 642/642 [38:34<00:00,  3.60s/it]
Waiting for the current checkpoint push to be finished, this might take a couple of minutes.
Saving model checkpoint to ./outputs/restem_6epoch
Configuration saved in ./outputs/restem_6epoch/config.json
Configuration saved in ./outputs/restem_6epoch/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
Saving model checkpoint to ./outputs/restem_6epoch
Configuration saved in ./outputs/restem_6epoch/config.json
Configuration saved in ./outputs/restem_6epoch/generation_config.json
The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./outputs/restem_6epoch/model.safetensors.index.json.
tokenizer config file saved in ./outputs/restem_6epoch/tokenizer_config.json
Special tokens file saved in ./outputs/restem_6epoch/special_tokens_map.json
Configuration saved in ./outputs/restem_6epoch/config.json
{'loss': 0.0991, 'grad_norm': 2.1875, 'learning_rate': 5.462520802998108e-06, 'epoch': 4.08}
{'loss': 0.0951, 'grad_norm': 3.234375, 'learning_rate': 5.221635213882295e-06, 'epoch': 4.13}
{'loss': 0.1023, 'grad_norm': 3.46875, 'learning_rate': 4.9842907444617415e-06, 'epoch': 4.18}
{'loss': 0.0941, 'grad_norm': 2.90625, 'learning_rate': 4.750663284442001e-06, 'epoch': 4.22}
{'loss': 0.0942, 'grad_norm': 2.984375, 'learning_rate': 4.52092596895131e-06, 'epoch': 4.27}
{'loss': 0.0941, 'grad_norm': 2.90625, 'learning_rate': 4.295249050234738e-06, 'epoch': 4.32}
{'loss': 0.0956, 'grad_norm': 3.046875, 'learning_rate': 4.073799771484768e-06, 'epoch': 4.36}
{'loss': 0.097, 'grad_norm': 2.578125, 'learning_rate': 3.8567422429017585e-06, 'epoch': 4.41}
{'loss': 0.0963, 'grad_norm': 2.546875, 'learning_rate': 3.644237320076256e-06, 'epoch': 4.45}
{'loss': 0.0993, 'grad_norm': 2.984375, 'learning_rate': 3.436442484783138e-06, 'epoch': 4.5}
{'loss': 0.0954, 'grad_norm': 3.015625, 'learning_rate': 3.2335117282760563e-06, 'epoch': 4.55}
{'loss': 0.0967, 'grad_norm': 2.890625, 'learning_rate': 3.0355954371685948e-06, 'epoch': 4.59}
{'loss': 0.0988, 'grad_norm': 2.40625, 'learning_rate': 2.842840281986726e-06, 'epoch': 4.64}
{'loss': 0.0976, 'grad_norm': 2.78125, 'learning_rate': 2.6553891084751604e-06, 'epoch': 4.69}
{'loss': 0.094, 'grad_norm': 3.578125, 'learning_rate': 2.473380831738146e-06, 'epoch': 4.73}
{'loss': 0.0956, 'grad_norm': 2.5625, 'learning_rate': 2.2969503332931754e-06, 'epoch': 4.78}
{'loss': 0.0988, 'grad_norm': 3.0, 'learning_rate': 2.126228361113839e-06, 'epoch': 4.83}
{'loss': 0.098, 'grad_norm': 2.703125, 'learning_rate': 1.9613414327359824e-06, 'epoch': 4.87}
{'loss': 0.0968, 'grad_norm': 2.71875, 'learning_rate': 1.8024117414989007e-06, 'epoch': 4.92}
{'loss': 0.0938, 'grad_norm': 2.75, 'learning_rate': 1.649557065991081e-06, 'epoch': 4.97}
{'loss': 0.0965, 'grad_norm': 1.75, 'learning_rate': 1.5028906827676148e-06, 'epoch': 5.01}
{'loss': 0.0829, 'grad_norm': 1.84375, 'learning_rate': 1.3625212824039468e-06, 'epoch': 5.06}
{'loss': 0.0819, 'grad_norm': 2.015625, 'learning_rate': 1.228552888948149e-06, 'epoch': 5.1}
{'loss': 0.082, 'grad_norm': 2.078125, 'learning_rate': 1.1010847828314708e-06, 'epoch': 5.15}
{'loss': 0.0849, 'grad_norm': 2.109375, 'learning_rate': 9.80211427294222e-07, 'epoch': 5.2}
{'loss': 0.0807, 'grad_norm': 1.875, 'learning_rate': 8.660223983815708e-07, 'epoch': 5.24}
{'loss': 0.0866, 'grad_norm': 2.359375, 'learning_rate': 7.586023185611136e-07, 'epoch': 5.29}
{'loss': 0.0844, 'grad_norm': 2.078125, 'learning_rate': 6.580307940113972e-07, 'epoch': 5.34}
{'loss': 0.0846, 'grad_norm': 1.953125, 'learning_rate': 5.643823556278849e-07, 'epoch': 5.38}
{'loss': 0.0841, 'grad_norm': 2.15625, 'learning_rate': 4.777264037900841e-07, 'epoch': 5.43}
{'loss': 0.0816, 'grad_norm': 1.640625, 'learning_rate': 3.981271569307654e-07, 'epoch': 5.48}
{'loss': 0.0845, 'grad_norm': 1.7578125, 'learning_rate': 3.2564360394537696e-07, 'epoch': 5.52}
{'loss': 0.0823, 'grad_norm': 2.109375, 'learning_rate': 2.6032946047693794e-07, 'epoch': 5.57}
{'loss': 0.0829, 'grad_norm': 2.03125, 'learning_rate': 2.02233129108792e-07, 'epoch': 5.61}
{'loss': 0.0829, 'grad_norm': 2.046875, 'learning_rate': 1.5139766349474004e-07, 'epoch': 5.66}
{'loss': 0.085, 'grad_norm': 2.078125, 'learning_rate': 1.0786073645311035e-07, 'epoch': 5.71}
{'loss': 0.0842, 'grad_norm': 2.078125, 'learning_rate': 7.165461204843738e-08, 'epoch': 5.75}
{'loss': 0.0809, 'grad_norm': 2.265625, 'learning_rate': 4.2806121681409076e-08, 'epoch': 5.8}
{'loss': 0.08, 'grad_norm': 1.90625, 'learning_rate': 2.1336644204834613e-08, 'epoch': 5.85}
{'loss': 0.0871, 'grad_norm': 2.390625, 'learning_rate': 7.262090080331075e-09, 'epoch': 5.89}
{'loss': 0.0866, 'grad_norm': 1.921875, 'learning_rate': 5.92889587515133e-10, 'epoch': 5.94}
{'train_runtime': 2315.0788, 'train_samples_per_second': 8.936, 'train_steps_per_second': 0.277, 'train_loss': 0.40725265422435564, 'epoch': 5.96}
***** train metrics *****
  epoch                    =     5.9582
  total_flos               = 60783083GF
  train_loss               =     0.4073
  train_runtime            = 0:38:35.07
  train_samples            =       3448
  train_samples_per_second =      8.936
  train_steps_per_second   =      0.277
Model saved to ./outputs/restem_6epoch
[1;34mwandb[0m: 🚀 View run [33mgemma2-2b-restem[0m at: [34mhttps://wandb.ai/yutongyin/huggingface/runs/7oikn82h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241113_055605-7oikn82h/logs[0m
