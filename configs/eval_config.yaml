model_name_or_path: "unsloth/llama-3-8b-instruct"
model_dtype: "bfloat16"
max_tokens: 1536
batch_size: 5000
eval_ratio: 1.0
output_file: "outputs/llama-3-8b-instruct-accuracy.txt"