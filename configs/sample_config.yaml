model_name_or_path: "unsloth/llama-3-8b-Instruct"
model_dtype: "bfloat16"
top_k: 40
top_p: 1.0
temperature: 0.7
max_tokens: 1536
sample_batch_size: 4
cutoff: 10
dataset_kwargs:
  MATH:
    problem_size: 32
    sample_size: 32
output_file: "outputs/sample_output.jsonl"