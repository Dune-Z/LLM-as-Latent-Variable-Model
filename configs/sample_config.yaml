model_name_or_path: "unsloth/llama-3-8b-Instruct"
checkpoint_path: "outputs/llama-3-8b-instruct-restem"
model_dtype: "bfloat16"
top_k: 40
top_p: 1.0
temperature: 0.7
max_tokens: 1536
repetition_penalty: 1.1
sample_batch_size: 16
cutoff: 1
dataset_kwargs:
  METAMATH:
    problem_size: -1
    sample_size: 32
output_file: "outputs/sample_output.jsonl"
verification_model: "gpt-4-turbo"